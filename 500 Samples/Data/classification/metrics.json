{
  "method": "Model Distillation (Zero-Shot Teacher \u2192 SBERT+LogReg Student)",
  "teacher_model": "facebook/bart-large-mnli",
  "student_model": "all-MiniLM-L6-v2 + LogisticRegression",
  "num_classes": 10,
  "classes": [
    "Applications",
    "Information_Extraction",
    "Language_Models",
    "ML_Methods",
    "Machine_Translation",
    "NLP_Core",
    "QA_Dialogue",
    "Sentiment_Opinion",
    "Speech_Audio",
    "Vision_Language"
  ],
  "f1_macro": 0.15189974457215838,
  "f1_weighted": 0.505514687100894,
  "train_size": 399,
  "test_size": 100
}