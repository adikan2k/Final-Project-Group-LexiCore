paper_id,title,authors,abstract,venue,year,categories,source,metadata,title_length,abstract_length,num_authors,num_categories,combined_text,cluster_id
arxiv_2511.02401v1,Generalization in Representation Models via Random Matrix Theory: Application to Recurrent Networks,['Yessin Moakher' 'Malik Tiomoko' 'Cosme Louart' 'Zhenyu Liao'],"We first study the generalization error of models that use a fixed feature representation (frozen intermediate layers) followed by a trainable readout layer. This setting encompasses a range of architectures, from deep random-feature models to echo-state networks (ESNs) with recurrent dynamics. Working in the high-dimensional regime, we apply Random Matrix Theory to derive a closed-form expression for the asymptotic generalization error. We then apply this analysis to recurrent representations and obtain concise formula that characterize their performance. Surprisingly, we show that a linear ESN is equivalent to ridge regression with an exponentially time-weighted (''memory'') input covariance, revealing a clear inductive bias toward recent inputs. Experiments match predictions: ESNs win in low-sample, short-memory regimes, while ridge prevails with more data or long-range dependencies. Our methodology provides a general framework for analyzing overparameterized models and offers insights into the behavior of deep learning networks.",arXiv,2025,['math.ST' 'cs.LG' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.02401v1', 'primary_category': 'math.ST', 'publication_date': None, 'published': '2025-11-04T09:30:31+00:00', 'reference_count': None}",99,1048,4,0,"Generalization in Representation Models via Random Matrix Theory: Application to Recurrent Networks. We first study the generalization error of models that use a fixed feature representation (frozen intermediate layers) followed by a trainable readout layer. This setting encompasses a range of architectures, from deep random-feature models to echo-state networks (ESNs) with recurrent dynamics. Working in the high-dimensional regime, we apply Random Matrix Theory to derive a closed-form expression for the asymptotic generalization error. We then apply this analysis to recurrent representations and obtain concise formula that characterize their performance. Surprisingly, we show that a linear ESN is equivalent to ridge regression with an exponentially time-weighted (''memory'') input covariance, revealing a clear inductive bias toward recent inputs. Experiments match predictions: ESNs win in low-sample, short-memory regimes, while ridge prevails with more data or long-range dependencies. Our methodology provides a general framework for analyzing overparameterized models and offers insights into the behavior of deep learning networks.",3
arxiv_2511.14406v1,Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation,['Bastien Vuillod' 'Pierre-Alain Moellic' 'Jean-Max Dutertre'],"Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.",arXiv,2025,['cs.LG' 'cs.CR'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14406v1', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-18T12:13:59+00:00', 'reference_count': None}",90,1161,3,0,"Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation. Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.",0
arxiv_2511.14617v1,Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning,"['Ruoyu Qin' 'Weiran He' 'Weixiao Huang' 'Yangkun Zhang' 'Yikai Zhao'
 'Bo Pang' 'Xinran Xu' 'Yingdi Shan' 'Yongwei Wu' 'Mingxing Zhang']","Reinforcement Learning (RL) has become critical for advancing modern Large Language Models (LLMs), yet existing synchronous RL systems face severe performance bottlenecks. The rollout phase, which dominates end-to-end iteration time, suffers from substantial long-tail latency and poor resource utilization due to inherent workload imbalance. We present Seer, a novel online context learning system that addresses these challenges by exploiting previously overlooked similarities in output lengths and generation patterns among requests sharing the same prompt. Seer introduces three key techniques: divided rollout for dynamic load balancing, context-aware scheduling, and adaptive grouped speculative decoding. Together, these mechanisms substantially reduce long-tail latency and improve resource efficiency during rollout. Evaluations on production-grade RL workloads demonstrate that Seer improves end-to-end rollout throughput by 74% to 97% and reduces long-tail latency by 75% to 93% compared to state-of-the-art synchronous RL systems, significantly accelerating RL training iterations.",arXiv,2025,['cs.DC' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14617v1', 'primary_category': 'cs.DC', 'publication_date': None, 'published': '2025-11-18T16:12:21+00:00', 'reference_count': None}",77,1094,10,0,"Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning. Reinforcement Learning (RL) has become critical for advancing modern Large Language Models (LLMs), yet existing synchronous RL systems face severe performance bottlenecks. The rollout phase, which dominates end-to-end iteration time, suffers from substantial long-tail latency and poor resource utilization due to inherent workload imbalance. We present Seer, a novel online context learning system that addresses these challenges by exploiting previously overlooked similarities in output lengths and generation patterns among requests sharing the same prompt. Seer introduces three key techniques: divided rollout for dynamic load balancing, context-aware scheduling, and adaptive grouped speculative decoding. Together, these mechanisms substantially reduce long-tail latency and improve resource efficiency during rollout. Evaluations on production-grade RL workloads demonstrate that Seer improves end-to-end rollout throughput by 74% to 97% and reduces long-tail latency by 75% to 93% compared to state-of-the-art synchronous RL systems, significantly accelerating RL training iterations.",2
s2_13a0d8bb38f739990c8cd65a44061c6534f17221,OPT: Open Pre-trained Transformer Language Models,"['Susan Zhang' 'Stephen Roller' 'Naman Goyal' 'Mikel Artetxe' 'Moya Chen'
 'Shuohui Chen' 'Christopher Dewan' 'Mona T. Diab' 'Xian Li'
 'Xi Victoria Lin' 'Todor Mihaylov' 'Myle Ott' 'Sam Shleifer'
 'Kurt Shuster' 'Daniel Simig' 'Punit Singh Koura' 'Anjali Sridhar'
 'Tianlu Wang' 'Luke Zettlemoyer']","Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.",arXiv.org,2022,['Computer Science'],s2orc,"{'citation_count': 4221.0, 'external_ids': {'ACL': None, 'ArXiv': '2205.01068', 'CorpusId': 248496292.0, 'DBLP': 'journals/corr/abs-2205-01068', 'DOI': None, 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2022-05-02', 'published': None, 'reference_count': 120.0}",49,848,19,0,"OPT: Open Pre-trained Transformer Language Models. Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.",2
s2_ab9cc2c6a8d35d7a145cf608ff9dd7af87213253,RUBi: Reducing Unimodal Biases in Visual Question Answering,['Rémi Cadène' 'Corentin Dancette' 'H. Ben-younes' 'M. Cord' 'Devi Parikh'],"Visual Question Answering (VQA) is the task of answering questions about an image. Some VQA models often exploit unimodal biases to provide the correct answer without using the image information. As a result, they suffer from a huge drop in performance when evaluated on data outside their training set distribution. This critical issue makes them unsuitable for real-world settings. 
We propose RUBi, a new learning strategy to reduce biases in any VQA model. It reduces the importance of the most biased examples, i.e. examples that can be correctly classified without looking at the image. It implicitly forces the VQA model to use the two input modalities instead of relying on statistical regularities between the question and the answer. We leverage a question-only model that captures the language biases by identifying when these unwanted regularities are used. It prevents the base VQA model from learning them by influencing its predictions. This leads to dynamically adjusting the loss in order to compensate for biases. We validate our contributions by surpassing the current state-of-the-art results on VQA-CP v2. This dataset is specifically designed to assess the robustness of VQA models when exposed to different question biases at test time than what was seen during training. 
Our code is available: this http URL",Neural Information Processing Systems,2019,['Computer Science'],s2orc,"{'citation_count': 396.0, 'external_ids': {'ACL': None, 'ArXiv': '1906.10169', 'CorpusId': 195584122.0, 'DBLP': 'conf/nips/CadeneDBCP19', 'DOI': None, 'MAG': '2970017794', 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2019-06-01', 'published': None, 'reference_count': 45.0}",59,1332,5,0,"RUBi: Reducing Unimodal Biases in Visual Question Answering. Visual Question Answering (VQA) is the task of answering questions about an image. Some VQA models often exploit unimodal biases to provide the correct answer without using the image information. As a result, they suffer from a huge drop in performance when evaluated on data outside their training set distribution. This critical issue makes them unsuitable for real-world settings. 
We propose RUBi, a new learning strategy to reduce biases in any VQA model. It reduces the importance of the most biased examples, i.e. examples that can be correctly classified without looking at the image. It implicitly forces the VQA model to use the two input modalities instead of relying on statistical regularities between the question and the answer. We leverage a question-only model that captures the language biases by identifying when these unwanted regularities are used. It prevents the base VQA model from learning them by influencing its predictions. This leads to dynamically adjusting the loss in order to compensate for biases. We validate our contributions by surpassing the current state-of-the-art results on VQA-CP v2. This dataset is specifically designed to assess the robustness of VQA models when exposed to different question biases at test time than what was seen during training. 
Our code is available: this http URL",1
s2_84c1102305595155feb33fa7ebdc37f3310b571e,ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training Quantization Framework for W8A8 Transformers,"['Zhewei Yao' 'Reza Yazdani Aminabadi' 'Stephen Youn' 'Xiaoxia Wu'
 'Elton Zheng' 'Yuxiong He']","Quantization techniques are pivotal in reducing the memory and computational demands of deep neural network inference. Existing solutions, such as ZeroQuant, offer dynamic quantization for models like BERT and GPT but overlook crucial memory-bounded operators and the complexities of per-token quantization. Addressing these gaps, we present a novel, fully hardware-enhanced robust optimized post-training W8A8 quantization framework, ZeroQuant-HERO. This framework uniquely integrates both memory bandwidth and compute-intensive operators, aiming for optimal hardware performance. Additionally, it offers flexibility by allowing specific INT8 modules to switch to FP16/BF16 mode, enhancing accuracy.",arXiv.org,2023,['Computer Science'],s2orc,"{'citation_count': 2.0, 'external_ids': {'ACL': None, 'ArXiv': '2310.17723', 'CorpusId': 264555298.0, 'DBLP': 'journals/corr/abs-2310-17723', 'DOI': '10.48550/arXiv.2310.17723', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2023-10-26', 'published': None, 'reference_count': 25.0}",109,700,6,0,"ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training Quantization Framework for W8A8 Transformers. Quantization techniques are pivotal in reducing the memory and computational demands of deep neural network inference. Existing solutions, such as ZeroQuant, offer dynamic quantization for models like BERT and GPT but overlook crucial memory-bounded operators and the complexities of per-token quantization. Addressing these gaps, we present a novel, fully hardware-enhanced robust optimized post-training W8A8 quantization framework, ZeroQuant-HERO. This framework uniquely integrates both memory bandwidth and compute-intensive operators, aiming for optimal hardware performance. Additionally, it offers flexibility by allowing specific INT8 modules to switch to FP16/BF16 mode, enhancing accuracy.",3
s2_35b142ea69598e6241f0011312128031df55895c,DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models,"['Zhihong Shao' 'Peiyi Wang' 'Qihao Zhu' 'R. Xu' 'Jun-Mei Song'
 'Mingchuan Zhang' 'Y. K. Li' 'Yu Wu' 'Daya Guo']","Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.",arXiv.org,2024,['Computer Science'],s2orc,"{'citation_count': 3139.0, 'external_ids': {'ACL': None, 'ArXiv': '2402.03300', 'CorpusId': 267412607.0, 'DBLP': 'journals/corr/abs-2402-03300', 'DOI': '10.48550/arXiv.2402.03300', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2024-02-05', 'published': None, 'reference_count': 57.0}",82,1053,9,0,"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models. Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.",2
s2_7e42377dbaa3af86bcba0ccd614c6c0a4a7bd6a3,Unsupervised Person Image Generation With Semantic Parsing Transformation,['Sijie Song' 'Wei Zhang' 'Jiaying Liu' 'Tao Mei'],"In this paper, we address unsupervised pose-guided person image generation, which is known challenging due to non-rigid deformation. Unlike previous methods learning a rock-hard direct mapping between human bodies, we propose a new pathway to decompose the hard mapping into two more accessible subtasks, namely, semantic parsing transformation and appearance generation. Firstly, a semantic generative network is proposed to transform between semantic parsing maps, in order to simplify the non-rigid deformation learning. Secondly, an appearance generative network learns to synthesize semantic-aware textures. Thirdly, we demonstrate that training our framework in an end-to-end manner further refines the semantic maps and final results accordingly. Our method is generalizable to other semantic-aware person image generation tasks, e.g., clothing texture transfer and controlled image manipulation. Experimental results demonstrate the superiority of our method on DeepFashion and Market-1501 datasets, especially in keeping the clothing attributes and better body shapes.",Computer Vision and Pattern Recognition,2019,['Computer Science'],s2orc,"{'citation_count': 106.0, 'external_ids': {'ACL': None, 'ArXiv': '1904.03379', 'CorpusId': 102352602.0, 'DBLP': 'conf/cvpr/SongZLM19', 'DOI': '10.1109/CVPR.2019.00246', 'MAG': '2933625230', 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2019-04-06', 'published': None, 'reference_count': 35.0}",73,1077,4,0,"Unsupervised Person Image Generation With Semantic Parsing Transformation. In this paper, we address unsupervised pose-guided person image generation, which is known challenging due to non-rigid deformation. Unlike previous methods learning a rock-hard direct mapping between human bodies, we propose a new pathway to decompose the hard mapping into two more accessible subtasks, namely, semantic parsing transformation and appearance generation. Firstly, a semantic generative network is proposed to transform between semantic parsing maps, in order to simplify the non-rigid deformation learning. Secondly, an appearance generative network learns to synthesize semantic-aware textures. Thirdly, we demonstrate that training our framework in an end-to-end manner further refines the semantic maps and final results accordingly. Our method is generalizable to other semantic-aware person image generation tasks, e.g., clothing texture transfer and controlled image manipulation. Experimental results demonstrate the superiority of our method on DeepFashion and Market-1501 datasets, especially in keeping the clothing attributes and better body shapes.",4
s2_1e33716e8820b867d5a8aaebab44c2d3135ea4ac,Make-A-Video: Text-to-Video Generation without Text-Video Data,"['Uriel Singer' 'Adam Polyak' 'Thomas Hayes' 'Xiaoyue Yin' 'Jie An'
 'Songyang Zhang' 'Qiyuan Hu' 'Harry Yang' 'Oron Ashual' 'Oran Gafni'
 'Devi Parikh' 'Sonal Gupta' 'Yaniv Taigman']","We propose Make-A-Video -- an approach for directly translating the tremendous recent progress in Text-to-Image (T2I) generation to Text-to-Video (T2V). Our intuition is simple: learn what the world looks like and how it is described from paired text-image data, and learn how the world moves from unsupervised video footage. Make-A-Video has three advantages: (1) it accelerates training of the T2V model (it does not need to learn visual and multimodal representations from scratch), (2) it does not require paired text-video data, and (3) the generated videos inherit the vastness (diversity in aesthetic, fantastical depictions, etc.) of today's image generation models. We design a simple yet effective way to build on T2I models with novel and effective spatial-temporal modules. First, we decompose the full temporal U-Net and attention tensors and approximate them in space and time. Second, we design a spatial temporal pipeline to generate high resolution and frame rate videos with a video decoder, interpolation model and two super resolution models that can enable various applications besides T2V. In all aspects, spatial and temporal resolution, faithfulness to text, and quality, Make-A-Video sets the new state-of-the-art in text-to-video generation, as determined by both qualitative and quantitative measures.",International Conference on Learning Representations,2022,['Computer Science'],s2orc,"{'citation_count': 1701.0, 'external_ids': {'ACL': None, 'ArXiv': '2209.14792', 'CorpusId': 252595919.0, 'DBLP': 'conf/iclr/SingerPH00ZHYAG23', 'DOI': None, 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2022-09-29', 'published': None, 'reference_count': 51.0}",62,1328,13,0,"Make-A-Video: Text-to-Video Generation without Text-Video Data. We propose Make-A-Video -- an approach for directly translating the tremendous recent progress in Text-to-Image (T2I) generation to Text-to-Video (T2V). Our intuition is simple: learn what the world looks like and how it is described from paired text-image data, and learn how the world moves from unsupervised video footage. Make-A-Video has three advantages: (1) it accelerates training of the T2V model (it does not need to learn visual and multimodal representations from scratch), (2) it does not require paired text-video data, and (3) the generated videos inherit the vastness (diversity in aesthetic, fantastical depictions, etc.) of today's image generation models. We design a simple yet effective way to build on T2I models with novel and effective spatial-temporal modules. First, we decompose the full temporal U-Net and attention tensors and approximate them in space and time. Second, we design a spatial temporal pipeline to generate high resolution and frame rate videos with a video decoder, interpolation model and two super resolution models that can enable various applications besides T2V. In all aspects, spatial and temporal resolution, faithfulness to text, and quality, Make-A-Video sets the new state-of-the-art in text-to-video generation, as determined by both qualitative and quantitative measures.",4
arxiv_2511.15010v1,Latent space analysis and generalization to out-of-distribution data,"['Katie Rainey' 'Erin Hausmann' 'Donald Waagen' 'David Gray'
 'Donald Hulsey']","Understanding the relationships between data points in the latent decision space derived by the deep learning system is critical to evaluating and interpreting the performance of the system on real world data. Detecting \textit{out-of-distribution} (OOD) data for deep learning systems continues to be an active research topic. We investigate the connection between latent space OOD detection and classification accuracy of the model. Using open source simulated and measured Synthetic Aperture RADAR (SAR) datasets, we empirically demonstrate that the OOD detection cannot be used as a proxy measure for model performance. We hope to inspire additional research into the geometric properties of the latent space that may yield future insights into deep learning robustness and generalizability.",arXiv,2025,['stat.ML' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.15010v1', 'primary_category': 'stat.ML', 'publication_date': None, 'published': '2025-11-19T01:23:34+00:00', 'reference_count': None}",68,795,5,0,"Latent space analysis and generalization to out-of-distribution data. Understanding the relationships between data points in the latent decision space derived by the deep learning system is critical to evaluating and interpreting the performance of the system on real world data. Detecting \textit{out-of-distribution} (OOD) data for deep learning systems continues to be an active research topic. We investigate the connection between latent space OOD detection and classification accuracy of the model. Using open source simulated and measured Synthetic Aperture RADAR (SAR) datasets, we empirically demonstrate that the OOD detection cannot be used as a proxy measure for model performance. We hope to inspire additional research into the geometric properties of the latent space that may yield future insights into deep learning robustness and generalizability.",3
arxiv_2511.13040v1,How Good is BLI as an Alignment Measure: A Study in Word Embedding Paradigm,['Kasun Wickramasinghe' 'Nisansa de Silva'],"Sans a dwindling number of monolingual embedding studies originating predominantly from the low-resource domains, it is evident that multilingual embedding has become the de facto choice due to its adaptability to the usage of code-mixed languages, granting the ability to process multilingual documents in a language-agnostic manner, as well as removing the difficult task of aligning monolingual embeddings. But is this victory complete? Are the multilingual models better than aligned monolingual models in every aspect? Can the higher computational cost of multilingual models always be justified? Or is there a compromise between the two extremes? Bilingual Lexicon Induction is one of the most widely used metrics in terms of evaluating the degree of alignment between two embedding spaces. In this study, we explore the strengths and limitations of BLI as a measure to evaluate the degree of alignment of two embedding spaces. Further, we evaluate how well traditional embedding alignment techniques, novel multilingual models, and combined alignment techniques perform BLI tasks in the contexts of both high-resource and low-resource languages. In addition to that, we investigate the impact of the language families to which the pairs of languages belong. We identify that BLI does not measure the true degree of alignment in some cases and we propose solutions for them. We propose a novel stem-based BLI approach to evaluate two aligned embedding spaces that take into account the inflected nature of languages as opposed to the prevalent word-based BLI techniques. Further, we introduce a vocabulary pruning technique that is more informative in showing the degree of the alignment, especially performing BLI on multilingual embedding models. Often, combined embedding alignment techniques perform better while in certain cases multilingual embeddings perform better (mainly low-resource language cases).",arXiv,2025,['cs.CL'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.13040v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-17T06:41:41+00:00', 'reference_count': None}",75,1916,2,0,"How Good is BLI as an Alignment Measure: A Study in Word Embedding Paradigm. Sans a dwindling number of monolingual embedding studies originating predominantly from the low-resource domains, it is evident that multilingual embedding has become the de facto choice due to its adaptability to the usage of code-mixed languages, granting the ability to process multilingual documents in a language-agnostic manner, as well as removing the difficult task of aligning monolingual embeddings. But is this victory complete? Are the multilingual models better than aligned monolingual models in every aspect? Can the higher computational cost of multilingual models always be justified? Or is there a compromise between the two extremes? Bilingual Lexicon Induction is one of the most widely used metrics in terms of evaluating the degree of alignment between two embedding spaces. In this study, we explore the strengths and limitations of BLI as a measure to evaluate the degree of alignment of two embedding spaces. Further, we evaluate how well traditional embedding alignment techniques, novel multilingual models, and combined alignment techniques perform BLI tasks in the contexts of both high-resource and low-resource languages. In addition to that, we investigate the impact of the language families to which the pairs of languages belong. We identify that BLI does not measure the true degree of alignment in some cases and we propose solutions for them. We propose a novel stem-based BLI approach to evaluate two aligned embedding spaces that take into account the inflected nature of languages as opposed to the prevalent word-based BLI techniques. Further, we introduce a vocabulary pruning technique that is more informative in showing the degree of the alignment, especially performing BLI on multilingual embedding models. Often, combined embedding alignment techniques perform better while in certain cases multilingual embeddings perform better (mainly low-resource language cases).",4
arxiv_2511.04666v1,Forgetting is Everywhere,"['Ben Sanati' 'Thomas L. Lee' 'Trevor McInroe' 'Aidan Scannell'
 'Nikolay Malkin' 'David Abel' 'Amos Storkey']","A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data. Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning. We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. Our theory naturally yields a general measure of an algorithm's propensity to forget. To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning. We empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency. Together, these results establish a principled understanding of forgetting and lay the foundation for analysing and improving the information retention capabilities of general learning algorithms.",arXiv,2025,['cs.LG' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.04666v1', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-06T18:52:57+00:00', 'reference_count': None}",24,1150,7,0,"Forgetting is Everywhere. A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data. Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning. We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. Our theory naturally yields a general measure of an algorithm's propensity to forget. To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning. We empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency. Together, these results establish a principled understanding of forgetting and lay the foundation for analysing and improving the information retention capabilities of general learning algorithms.",0
arxiv_2511.14195v1,N-GLARE: An Non-Generative Latent Representation-Efficient LLM Safety Evaluator,['Zheyu Lin' 'Jirui Yang' 'Hengqi Guo' 'Yubing Bao' 'Yao Guan'],"Evaluating the safety robustness of LLMs is critical for their deployment. However, mainstream Red Teaming methods rely on online generation and black-box output analysis. These approaches are not only costly but also suffer from feedback latency, making them unsuitable for agile diagnostics after training a new model. To address this, we propose N-GLARE (A Non-Generative, Latent Representation-Efficient LLM Safety Evaluator). N-GLARE operates entirely on the model's latent representations, bypassing the need for full text generation. It characterizes hidden layer dynamics by analyzing the APT (Angular-Probabilistic Trajectory) of latent representations and introducing the JSS (Jensen-Shannon Separability) metric. Experiments on over 40 models and 20 red teaming strategies demonstrate that the JSS metric exhibits high consistency with the safety rankings derived from Red Teaming. N-GLARE reproduces the discriminative trends of large-scale red-teaming tests at less than 1\% of the token cost and the runtime cost, providing an efficient output-free evaluation proxy for real-time diagnostics.",arXiv,2025,['cs.LG' 'cs.CR'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14195v1', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-18T07:03:58+00:00', 'reference_count': None}",79,1106,5,0,"N-GLARE: An Non-Generative Latent Representation-Efficient LLM Safety Evaluator. Evaluating the safety robustness of LLMs is critical for their deployment. However, mainstream Red Teaming methods rely on online generation and black-box output analysis. These approaches are not only costly but also suffer from feedback latency, making them unsuitable for agile diagnostics after training a new model. To address this, we propose N-GLARE (A Non-Generative, Latent Representation-Efficient LLM Safety Evaluator). N-GLARE operates entirely on the model's latent representations, bypassing the need for full text generation. It characterizes hidden layer dynamics by analyzing the APT (Angular-Probabilistic Trajectory) of latent representations and introducing the JSS (Jensen-Shannon Separability) metric. Experiments on over 40 models and 20 red teaming strategies demonstrate that the JSS metric exhibits high consistency with the safety rankings derived from Red Teaming. N-GLARE reproduces the discriminative trends of large-scale red-teaming tests at less than 1\% of the token cost and the runtime cost, providing an efficient output-free evaluation proxy for real-time diagnostics.",2
s2_1e909e2a8cdacdcdff125ebcc566f37cb869a1c8,"A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions","['Lei Huang' 'Weijiang Yu' 'Weitao Ma' 'Weihong Zhong' 'Zhangyin Feng'
 'Haotian Wang' 'Qianglong Chen' 'Weihua Peng' 'Xiaocheng Feng' 'Bing Qin'
 'Ting Liu']","The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are prone to hallucination, generating plausible yet nonfactual content. This phenomenon raises significant concerns over the reliability of LLMs in real-world information retrieval (IR) systems and has attracted intensive research to detect and mitigate such hallucinations. Given the open-ended general-purpose attributes inherent to LLMs, LLM hallucinations present distinct challenges that diverge from prior task-specific models. This divergence highlights the urgency for a nuanced understanding and comprehensive overview of recent advances in LLM hallucinations. In this survey, we begin with an innovative taxonomy of hallucination in the era of LLM and then delve into the factors contributing to hallucinations. Subsequently, we present a thorough overview of hallucination detection methods and benchmarks. Our discussion then transfers to representative methodologies for mitigating LLM hallucinations. Additionally, we delve into the current limitations faced by retrieval-augmented LLMs in combating hallucinations, offering insights for developing more robust IR systems. Finally, we highlight the promising research directions on LLM hallucinations, including hallucination in large vision-language models and understanding of knowledge boundaries in LLM hallucinations.",ACM Trans. Inf. Syst.,2023,['Computer Science'],s2orc,"{'citation_count': 1629.0, 'external_ids': {'ACL': None, 'ArXiv': '2311.05232', 'CorpusId': 265067168.0, 'DBLP': 'journals/tois/HuangYMZFWCPFQL25', 'DOI': '10.1145/3703155', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2023-11-09', 'published': None, 'reference_count': 287.0}",104,1481,11,0,"A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions. The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are prone to hallucination, generating plausible yet nonfactual content. This phenomenon raises significant concerns over the reliability of LLMs in real-world information retrieval (IR) systems and has attracted intensive research to detect and mitigate such hallucinations. Given the open-ended general-purpose attributes inherent to LLMs, LLM hallucinations present distinct challenges that diverge from prior task-specific models. This divergence highlights the urgency for a nuanced understanding and comprehensive overview of recent advances in LLM hallucinations. In this survey, we begin with an innovative taxonomy of hallucination in the era of LLM and then delve into the factors contributing to hallucinations. Subsequently, we present a thorough overview of hallucination detection methods and benchmarks. Our discussion then transfers to representative methodologies for mitigating LLM hallucinations. Additionally, we delve into the current limitations faced by retrieval-augmented LLMs in combating hallucinations, offering insights for developing more robust IR systems. Finally, we highlight the promising research directions on LLM hallucinations, including hallucination in large vision-language models and understanding of knowledge boundaries in LLM hallucinations.",4
arxiv_2511.14953v1,Compiling to recurrent neurons,['Joey Velez-Ginorio' 'Nada Amin' 'Konrad Kording' 'Steve Zdancewic'],"Discrete structures are currently second-class in differentiable programming. Since functions over discrete structures lack overt derivatives, differentiable programs do not differentiate through them and limit where they can be used. For example, when programming a neural network, conditionals and iteration cannot be used everywhere; they can break the derivatives necessary for gradient-based learning to work. This limits the class of differentiable algorithms we can directly express, imposing restraints on how we build neural networks and differentiable programs more generally. However, these restraints are not fundamental. Recent work shows conditionals can be first-class, by compiling them into differentiable form as linear neurons. Similarly, this work shows iteration can be first-class -- by compiling to linear recurrent neurons. We present a minimal typed, higher-order and linear programming language with iteration called $\textsf{Cajal}\scriptstyle(\mathbb{\multimap}, \mathbb{2}, \mathbb{N})$. We prove its programs compile correctly to recurrent neurons, allowing discrete algorithms to be expressed in a differentiable form compatible with gradient-based learning. With our implementation, we conduct two experiments where we link these recurrent neurons against a neural network solving an iterative image transformation task. This determines part of its function prior to learning. As a result, the network learns faster and with greater data-efficiency relative to a neural network programmed without first-class iteration. A key lesson is that recurrent neurons enable a rich interplay between learning and the discrete structures of ordinary programming.",arXiv,2025,['cs.PL' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14953v1', 'primary_category': 'cs.PL', 'publication_date': None, 'published': '2025-11-18T22:26:27+00:00', 'reference_count': None}",30,1684,4,0,"Compiling to recurrent neurons. Discrete structures are currently second-class in differentiable programming. Since functions over discrete structures lack overt derivatives, differentiable programs do not differentiate through them and limit where they can be used. For example, when programming a neural network, conditionals and iteration cannot be used everywhere; they can break the derivatives necessary for gradient-based learning to work. This limits the class of differentiable algorithms we can directly express, imposing restraints on how we build neural networks and differentiable programs more generally. However, these restraints are not fundamental. Recent work shows conditionals can be first-class, by compiling them into differentiable form as linear neurons. Similarly, this work shows iteration can be first-class -- by compiling to linear recurrent neurons. We present a minimal typed, higher-order and linear programming language with iteration called $\textsf{Cajal}\scriptstyle(\mathbb{\multimap}, \mathbb{2}, \mathbb{N})$. We prove its programs compile correctly to recurrent neurons, allowing discrete algorithms to be expressed in a differentiable form compatible with gradient-based learning. With our implementation, we conduct two experiments where we link these recurrent neurons against a neural network solving an iterative image transformation task. This determines part of its function prior to learning. As a result, the network learns faster and with greater data-efficiency relative to a neural network programmed without first-class iteration. A key lesson is that recurrent neurons enable a rich interplay between learning and the discrete structures of ordinary programming.",0
s2_93b6b79b4ef6c345f31722ce7c829385c6dce0d6,Slake: A Semantically-Labeled Knowledge-Enhanced Dataset For Medical Visual Question Answering,['Bo Liu' 'Li-Ming Zhan' 'Li Xu' 'Lin Ma' 'Y. Yang' 'Xiao-Ming Wu'],"Medical visual question answering (Med-VQA) has tremendous potential in healthcare. However, the development of this technology is hindered by the lacking of publicly-available and high-quality labeled datasets for training and evaluation. In this paper, we present a large bilingual dataset, SLAKE, with comprehensive semantic labels annotated by experienced physicians and a new structural medical knowledge base for Med-VQA. Besides, SLAKE includes richer modalities and covers more human body parts than the currently available dataset. We show that SLAKE can be used to facilitate the development and evaluation of Med-VQA systems. The dataset can be downloaded from http://www.med-vqa.com/slake.",IEEE International Symposium on Biomedical Imaging,2021,['Computer Science'],s2orc,"{'citation_count': 400.0, 'external_ids': {'ACL': None, 'ArXiv': '2102.09542', 'CorpusId': 231951663.0, 'DBLP': 'journals/corr/abs-2102-09542', 'DOI': '10.1109/ISBI48211.2021.9434010', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2021-02-18', 'published': None, 'reference_count': 15.0}",94,701,6,0,"Slake: A Semantically-Labeled Knowledge-Enhanced Dataset For Medical Visual Question Answering. Medical visual question answering (Med-VQA) has tremendous potential in healthcare. However, the development of this technology is hindered by the lacking of publicly-available and high-quality labeled datasets for training and evaluation. In this paper, we present a large bilingual dataset, SLAKE, with comprehensive semantic labels annotated by experienced physicians and a new structural medical knowledge base for Med-VQA. Besides, SLAKE includes richer modalities and covers more human body parts than the currently available dataset. We show that SLAKE can be used to facilitate the development and evaluation of Med-VQA systems. The dataset can be downloaded from http://www.med-vqa.com/slake.",1
arxiv_2511.11258v1,KGQuest: Template-Driven QA Generation from Knowledge Graphs with LLM-Based Refinement,['Sania Nayab' 'Marco Simoni' 'Giulio Rossolini' 'Andrea Saracino'],"The generation of questions and answers (QA) from knowledge graphs (KG) plays a crucial role in the development and testing of educational platforms, dissemination tools, and large language models (LLM). However, existing approaches often struggle with scalability, linguistic quality, and factual consistency. This paper presents a scalable and deterministic pipeline for generating natural language QA from KGs, with an additional refinement step using LLMs to further enhance linguistic quality. The approach first clusters KG triplets based on their relations, creating reusable templates through natural language rules derived from the entity types of objects and relations. A module then leverages LLMs to refine these templates, improving clarity and coherence while preserving factual accuracy. Finally, the instantiation of answer options is achieved through a selection strategy that introduces distractors from the KG. Our experiments demonstrate that this hybrid approach efficiently generates high-quality QA pairs, combining scalability with fluency and linguistic precision.",arXiv,2025,['cs.CL' 'cs.AI'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.11258v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-14T12:54:01+00:00', 'reference_count': None}",86,1089,4,0,"KGQuest: Template-Driven QA Generation from Knowledge Graphs with LLM-Based Refinement. The generation of questions and answers (QA) from knowledge graphs (KG) plays a crucial role in the development and testing of educational platforms, dissemination tools, and large language models (LLM). However, existing approaches often struggle with scalability, linguistic quality, and factual consistency. This paper presents a scalable and deterministic pipeline for generating natural language QA from KGs, with an additional refinement step using LLMs to further enhance linguistic quality. The approach first clusters KG triplets based on their relations, creating reusable templates through natural language rules derived from the entity types of objects and relations. A module then leverages LLMs to refine these templates, improving clarity and coherence while preserving factual accuracy. Finally, the instantiation of answer options is achieved through a selection strategy that introduces distractors from the KG. Our experiments demonstrate that this hybrid approach efficiently generates high-quality QA pairs, combining scalability with fluency and linguistic precision.",1
arxiv_2511.14385v1,Mitigating Label Length Bias in Large Language Models,['Mario Sanz-Guerrero' 'Katharina von der Wense'],"Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.",arXiv,2025,['cs.CL'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14385v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-18T11:45:24+00:00', 'reference_count': None}",53,1244,2,0,"Mitigating Label Length Bias in Large Language Models. Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.",4
arxiv_2511.08717v2,Optimal control of the future via prospective learning with control,"['Yuxin Bai' 'Aranyak Acharyya' 'Ashwin De Silva' 'Zeyu Shen'
 'James Hassett' 'Joshua T. Vogelstein']","Optimal control of the future is the next frontier for AI. Current approaches to this problem are typically rooted in either reinforcement learning (RL). While powerful, this learning framework is mathematically distinct from supervised learning, which has been the main workhorse for the recent achievements in AI. Moreover, RL typically operates in a stationary environment with episodic resets, limiting its utility to more realistic settings. Here, we extend supervised learning to address learning to control in non-stationary, reset-free environments. Using this framework, called ''Prospective Learning with Control (PL+C)'', we prove that under certain fairly general assumptions, empirical risk minimization (ERM) asymptotically achieves the Bayes optimal policy. We then consider a specific instance of prospective learning with control, foraging -- which is a canonical task for any mobile agent -- be it natural or artificial. We illustrate that modern RL algorithms fail to learn in these non-stationary reset-free environments, and even with modifications, they are orders of magnitude less efficient than our prospective foraging agents.",arXiv,2025,['stat.ML' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.08717v2', 'primary_category': 'stat.ML', 'publication_date': None, 'published': '2025-11-11T19:27:14+00:00', 'reference_count': None}",67,1152,6,0,"Optimal control of the future via prospective learning with control. Optimal control of the future is the next frontier for AI. Current approaches to this problem are typically rooted in either reinforcement learning (RL). While powerful, this learning framework is mathematically distinct from supervised learning, which has been the main workhorse for the recent achievements in AI. Moreover, RL typically operates in a stationary environment with episodic resets, limiting its utility to more realistic settings. Here, we extend supervised learning to address learning to control in non-stationary, reset-free environments. Using this framework, called ''Prospective Learning with Control (PL+C)'', we prove that under certain fairly general assumptions, empirical risk minimization (ERM) asymptotically achieves the Bayes optimal policy. We then consider a specific instance of prospective learning with control, foraging -- which is a canonical task for any mobile agent -- be it natural or artificial. We illustrate that modern RL algorithms fail to learn in these non-stationary reset-free environments, and even with modifications, they are orders of magnitude less efficient than our prospective foraging agents.",0
arxiv_2511.14688v1,Ground Truth Generation for Multilingual Historical NLP using LLMs,['Clovis Gladstone' 'Zhao Fang' 'Spencer Dean Stewart'],"Historical and low-resource NLP remains challenging due to limited annotated data and domain mismatches with modern, web-sourced corpora. This paper outlines our work in using large language models (LLMs) to create ground-truth annotations for historical French (16th-20th centuries) and Chinese (1900-1950) texts. By leveraging LLM-generated ground truth on a subset of our corpus, we were able to fine-tune spaCy to achieve significant gains on period-specific tests for part-of-speech (POS) annotations, lemmatization, and named entity recognition (NER). Our results underscore the importance of domain-specific models and demonstrate that even relatively limited amounts of synthetic data can improve NLP tools for under-resourced corpora in computational humanities research.",arXiv,2025,['cs.CL' 'cs.AI'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14688v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-18T17:25:43+00:00', 'reference_count': None}",66,780,3,0,"Ground Truth Generation for Multilingual Historical NLP using LLMs. Historical and low-resource NLP remains challenging due to limited annotated data and domain mismatches with modern, web-sourced corpora. This paper outlines our work in using large language models (LLMs) to create ground-truth annotations for historical French (16th-20th centuries) and Chinese (1900-1950) texts. By leveraging LLM-generated ground truth on a subset of our corpus, we were able to fine-tune spaCy to achieve significant gains on period-specific tests for part-of-speech (POS) annotations, lemmatization, and named entity recognition (NER). Our results underscore the importance of domain-specific models and demonstrate that even relatively limited amounts of synthetic data can improve NLP tools for under-resourced corpora in computational humanities research.",4
arxiv_2511.15174v1,FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model,"['Yi Xu' 'Zhigang Chen' 'Rui Wang' 'Yangfan Li' 'Fengxiao Tang'
 'Ming Zhao' 'Jiaqi Liu']","In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.",arXiv,2025,['cs.LG' 'cs.AI'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.15174v1', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-19T06:53:15+00:00', 'reference_count': None}",74,1218,7,0,"FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model. In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.",3
arxiv_2511.05159v1,"A New Framework for Convex Clustering in Kernel Spaces: Finite Sample Bounds, Consistency and Performance Insights","['Shubhayan Pan' 'Saptarshi Chakraborty' 'Debolina Paul' 'Kushal Bose'
 'Swagatam Das']","Convex clustering is a well-regarded clustering method, resembling the similar centroid-based approach of Lloyd's $k$-means, without requiring a predefined cluster count. It starts with each data point as its centroid and iteratively merges them. Despite its advantages, this method can fail when dealing with data exhibiting linearly non-separable or non-convex structures. To mitigate the limitations, we propose a kernelized extension of the convex clustering method. This approach projects the data points into a Reproducing Kernel Hilbert Space (RKHS) using a feature map, enabling convex clustering in this transformed space. This kernelization not only allows for better handling of complex data distributions but also produces an embedding in a finite-dimensional vector space. We provide a comprehensive theoretical underpinnings for our kernelized approach, proving algorithmic convergence and establishing finite sample bounds for our estimates. The effectiveness of our method is demonstrated through extensive experiments on both synthetic and real-world datasets, showing superior performance compared to state-of-the-art clustering techniques. This work marks a significant advancement in the field, offering an effective solution for clustering in non-linear and non-convex data scenarios.",arXiv,2025,['stat.ML' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.05159v1', 'primary_category': 'stat.ML', 'publication_date': None, 'published': '2025-11-07T11:24:22+00:00', 'reference_count': None}",114,1305,5,0,"A New Framework for Convex Clustering in Kernel Spaces: Finite Sample Bounds, Consistency and Performance Insights. Convex clustering is a well-regarded clustering method, resembling the similar centroid-based approach of Lloyd's $k$-means, without requiring a predefined cluster count. It starts with each data point as its centroid and iteratively merges them. Despite its advantages, this method can fail when dealing with data exhibiting linearly non-separable or non-convex structures. To mitigate the limitations, we propose a kernelized extension of the convex clustering method. This approach projects the data points into a Reproducing Kernel Hilbert Space (RKHS) using a feature map, enabling convex clustering in this transformed space. This kernelization not only allows for better handling of complex data distributions but also produces an embedding in a finite-dimensional vector space. We provide a comprehensive theoretical underpinnings for our kernelized approach, proving algorithmic convergence and establishing finite sample bounds for our estimates. The effectiveness of our method is demonstrated through extensive experiments on both synthetic and real-world datasets, showing superior performance compared to state-of-the-art clustering techniques. This work marks a significant advancement in the field, offering an effective solution for clustering in non-linear and non-convex data scenarios.",3
arxiv_2511.12159v1,CriticSearch: Fine-Grained Credit Assignment for Search Agents via a Retrospective Critic,"['Yaocheng Zhang' 'Haohuan Huang' 'Zijun Song' 'Yuanheng Zhu'
 'Qichao Zhang' 'Zijie Zhao' 'Dongbin Zhao']","Tool-Integrated Reasoning (TIR) with search engines enables large language models to iteratively retrieve up-to-date external knowledge, enhancing adaptability and generalization in complex question-answering tasks. However, existing search agent pipelines typically depend on reinforcement learning based optimization, which often suffers from sparse outcome rewards, leading to inefficient exploration and unstable training. We introduce CriticSearch, a fine-grained credit-assignment framework that supplies dense, turn-level feedback via a retrospective critic mechanism. During training, a frozen, asymmetric critique LLM retrospectively evaluates each turn using privileged information from the full trajectory and gold answers, converting these assessments into stable, dense rewards that guide policy improvement. Experimental results across diverse multi-hop reasoning benchmarks demonstrate that CriticSearch consistently outperforms existing baselines, achieving faster convergence, improved training stability, and higher performance.",arXiv,2025,['cs.CL'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.12159v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-15T11:06:57+00:00', 'reference_count': None}",89,1046,7,0,"CriticSearch: Fine-Grained Credit Assignment for Search Agents via a Retrospective Critic. Tool-Integrated Reasoning (TIR) with search engines enables large language models to iteratively retrieve up-to-date external knowledge, enhancing adaptability and generalization in complex question-answering tasks. However, existing search agent pipelines typically depend on reinforcement learning based optimization, which often suffers from sparse outcome rewards, leading to inefficient exploration and unstable training. We introduce CriticSearch, a fine-grained credit-assignment framework that supplies dense, turn-level feedback via a retrospective critic mechanism. During training, a frozen, asymmetric critique LLM retrospectively evaluates each turn using privileged information from the full trajectory and gold answers, converting these assessments into stable, dense rewards that guide policy improvement. Experimental results across diverse multi-hop reasoning benchmarks demonstrate that CriticSearch consistently outperforms existing baselines, achieving faster convergence, improved training stability, and higher performance.",0
arxiv_2511.02757v1,ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models,"['Lejs Deen Behric' 'Liang Zhang' 'Bingcong Li'
 'Kiran Koshy Thekumparampil']","Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy for finetuning large language models (LLMs) because it eliminates the memory overhead of backpropagation. However, it converges slowly due to the inherent curse of dimensionality when searching for descent directions in the high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a novel zeroth-order optimizer that accelerates convergence by adaptive directional sampling. Instead of drawing the direction uniformly at random, ConMeZO restricts the sampling to a cone centered around a momentum estimate. This concentrates the search in directions where the true gradient is more likely to lie and thus reduces the effect of high dimensions. We prove that ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically, when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than MeZO while retaining the low-memory footprint of zeroth-order methods.",arXiv,2025,['cs.LG' 'math.OC' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.02757v1', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-04T17:35:52+00:00', 'reference_count': None}",98,981,4,0,"ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models. Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy for finetuning large language models (LLMs) because it eliminates the memory overhead of backpropagation. However, it converges slowly due to the inherent curse of dimensionality when searching for descent directions in the high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a novel zeroth-order optimizer that accelerates convergence by adaptive directional sampling. Instead of drawing the direction uniformly at random, ConMeZO restricts the sampling to a cone centered around a momentum estimate. This concentrates the search in directions where the true gradient is more likely to lie and thus reduces the effect of high dimensions. We prove that ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically, when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than MeZO while retaining the low-memory footprint of zeroth-order methods.",2
s2_990a7b4eceedb6e053e6386269481bdfc42a1094,CoQA: A Conversational Question Answering Challenge,['Siva Reddy' 'Danqi Chen' 'Christopher D. Manning'],"Humans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4%, which is 23.4 points behind human performance (88.8%), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github.io/coqa.",Transactions of the Association for Computational Linguistics,2018,['Computer Science'],s2orc,"{'citation_count': 1296.0, 'external_ids': {'ACL': 'Q19-1016', 'ArXiv': '1808.07042', 'CorpusId': 52055325.0, 'DBLP': 'journals/tacl/ReddyCM19', 'DOI': '10.1162/tacl_a_00266', 'MAG': '2888296173', 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2018-08-21', 'published': None, 'reference_count': 66.0}",51,1086,3,0,"CoQA: A Conversational Question Answering Challenge. Humans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4%, which is 23.4 points behind human performance (88.8%), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github.io/coqa.",1
arxiv_2511.06304v2,"Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation",['Kevin Bönisch' 'Leandro Losaria'],"Since 2010, Kaggle has been a platform where data scientists from around the world come together to compete, collaborate, and push the boundaries of Data Science. Over these 15 years, it has grown from a purely competition-focused site into a broader ecosystem with forums, notebooks, models, datasets, and more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now have a unique opportunity to explore these competitions, technologies, and real-world applications of Machine Learning and AI. And so in this study, we take a closer look at 15 years of data science on Kaggle - through metadata, shared code, community discussions, and the competitions themselves. We explore Kaggle's growth, its impact on the data science community, uncover hidden technological trends, analyze competition winners, how Kagglers approach problems in general, and more. We do this by analyzing millions of kernels and discussion threads to perform both longitudinal trend analysis and standard exploratory data analysis. Our findings show that Kaggle is a steadily growing platform with increasingly diverse use cases, and that Kagglers are quick to adapt to new trends and apply them to real-world challenges, while producing - on average - models with solid generalization capabilities. We also offer a snapshot of the platform as a whole, highlighting its history and technological evolution. Finally, this study is accompanied by a video (https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up (https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi) for your convenience.",arXiv,2025,['cs.LG' 'cs.AI' 'cs.GL' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.06304v2', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-09T10:01:39+00:00', 'reference_count': None}",82,1651,2,0,"Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation. Since 2010, Kaggle has been a platform where data scientists from around the world come together to compete, collaborate, and push the boundaries of Data Science. Over these 15 years, it has grown from a purely competition-focused site into a broader ecosystem with forums, notebooks, models, datasets, and more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now have a unique opportunity to explore these competitions, technologies, and real-world applications of Machine Learning and AI. And so in this study, we take a closer look at 15 years of data science on Kaggle - through metadata, shared code, community discussions, and the competitions themselves. We explore Kaggle's growth, its impact on the data science community, uncover hidden technological trends, analyze competition winners, how Kagglers approach problems in general, and more. We do this by analyzing millions of kernels and discussion threads to perform both longitudinal trend analysis and standard exploratory data analysis. Our findings show that Kaggle is a steadily growing platform with increasingly diverse use cases, and that Kagglers are quick to adapt to new trends and apply them to real-world challenges, while producing - on average - models with solid generalization capabilities. We also offer a snapshot of the platform as a whole, highlighting its history and technological evolution. Finally, this study is accompanied by a video (https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up (https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi) for your convenience.",4
s2_f197bf0fc2f228483f6af3285000d54d8d97f9eb,Voyager: An Open-Ended Embodied Agent with Large Language Models,"['Guanzhi Wang' 'Yuqi Xie' 'Yunfan Jiang' 'Ajay Mandlekar' 'Chaowei Xiao'
 'Yuke Zhu' 'Linxi (Jim) Fan' 'Anima Anandkumar']","We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize. We open-source our full codebase and prompts at https://voyager.minedojo.org/.",Trans. Mach. Learn. Res.,2023,['Computer Science'],s2orc,"{'citation_count': 1092.0, 'external_ids': {'ACL': None, 'ArXiv': '2305.16291', 'CorpusId': 258887849.0, 'DBLP': 'journals/corr/abs-2305-16291', 'DOI': '10.48550/arXiv.2305.16291', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2023-05-25', 'published': None, 'reference_count': 89.0}",64,1347,8,0,"Voyager: An Open-Ended Embodied Agent with Large Language Models. We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize. We open-source our full codebase and prompts at https://voyager.minedojo.org/.",2
arxiv_2511.06425v1,Non-Negative Stiefel Approximating Flow: Orthogonalish Matrix Optimization for Interpretable Embeddings,['Brian B. Avants' 'Nicholas J. Tustison' 'James R Stone'],"Interpretable representation learning is a central challenge in modern machine learning, particularly in high-dimensional settings such as neuroimaging, genomics, and text analysis. Current methods often struggle to balance the competing demands of interpretability and model flexibility, limiting their effectiveness in extracting meaningful insights from complex data. We introduce Non-negative Stiefel Approximating Flow (NSA-Flow), a general-purpose matrix estimation framework that unifies ideas from sparse matrix factorization, orthogonalization, and constrained manifold learning. NSA-Flow enforces structured sparsity through a continuous balance between reconstruction fidelity and column-wise decorrelation, parameterized by a single tunable weight. The method operates as a smooth flow near the Stiefel manifold with proximal updates for non-negativity and adaptive gradient control, yielding representations that are simultaneously sparse, stable, and interpretable. Unlike classical regularization schemes, NSA-Flow provides an intuitive geometric mechanism for manipulating sparsity at the level of global structure while simplifying latent features. We demonstrate that the NSA-Flow objective can be optimized smoothly and integrates seamlessly with existing pipelines for dimensionality reduction while improving interpretability and generalization in both simulated and real biomedical data. Empirical validation on the Golub leukemia dataset and in Alzheimer's disease demonstrate that the NSA-Flow constraints can maintain or improve performance over related methods with little additional methodological effort. NSA-Flow offers a scalable, general-purpose tool for interpretable ML, applicable across data science domains.",arXiv,2025,['stat.ML' 'cs.CV' 'cs.LG' 'stat.ME'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.06425v1', 'primary_category': 'stat.ML', 'publication_date': None, 'published': '2025-11-09T15:43:43+00:00', 'reference_count': None}",103,1743,3,0,"Non-Negative Stiefel Approximating Flow: Orthogonalish Matrix Optimization for Interpretable Embeddings. Interpretable representation learning is a central challenge in modern machine learning, particularly in high-dimensional settings such as neuroimaging, genomics, and text analysis. Current methods often struggle to balance the competing demands of interpretability and model flexibility, limiting their effectiveness in extracting meaningful insights from complex data. We introduce Non-negative Stiefel Approximating Flow (NSA-Flow), a general-purpose matrix estimation framework that unifies ideas from sparse matrix factorization, orthogonalization, and constrained manifold learning. NSA-Flow enforces structured sparsity through a continuous balance between reconstruction fidelity and column-wise decorrelation, parameterized by a single tunable weight. The method operates as a smooth flow near the Stiefel manifold with proximal updates for non-negativity and adaptive gradient control, yielding representations that are simultaneously sparse, stable, and interpretable. Unlike classical regularization schemes, NSA-Flow provides an intuitive geometric mechanism for manipulating sparsity at the level of global structure while simplifying latent features. We demonstrate that the NSA-Flow objective can be optimized smoothly and integrates seamlessly with existing pipelines for dimensionality reduction while improving interpretability and generalization in both simulated and real biomedical data. Empirical validation on the Golub leukemia dataset and in Alzheimer's disease demonstrate that the NSA-Flow constraints can maintain or improve performance over related methods with little additional methodological effort. NSA-Flow offers a scalable, general-purpose tool for interpretable ML, applicable across data science domains.",3
arxiv_2511.14868v1,Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings,"['Xueying Ding' 'Xingyue Huang' 'Mingxuan Ju' 'Liam Collins' 'Yozen Liu'
 'Leman Akoglu' 'Neil Shah' 'Tong Zhao']","Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a single summary token, they over-compress information, hence harming performance on long documents. We propose Hierarchical Token Prepending (HTP), a method that resolves two critical bottlenecks. To mitigate attention-level compression, HTP partitions the input into blocks and prepends block-level summary tokens to subsequent blocks, creating multiple pathways for backward information flow. To address readout-level over-squashing, we replace last-token pooling with mean-pooling, a choice supported by theoretical analysis. HTP achieves consistent performance gains across 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context settings. As a simple, architecture-agnostic method, HTP enhances both zero-shot and finetuned models, offering a scalable route to superior long-document embeddings.",arXiv,2025,['cs.CL' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14868v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-18T19:37:40+00:00', 'reference_count': None}",89,1079,8,0,"Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings. Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a single summary token, they over-compress information, hence harming performance on long documents. We propose Hierarchical Token Prepending (HTP), a method that resolves two critical bottlenecks. To mitigate attention-level compression, HTP partitions the input into blocks and prepends block-level summary tokens to subsequent blocks, creating multiple pathways for backward information flow. To address readout-level over-squashing, we replace last-token pooling with mean-pooling, a choice supported by theoretical analysis. HTP achieves consistent performance gains across 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context settings. As a simple, architecture-agnostic method, HTP enhances both zero-shot and finetuned models, offering a scalable route to superior long-document embeddings.",4
arxiv_2511.15332v1,Exponential Lasso: robust sparse penalization under heavy-tailed noise and outliers with exponential-type loss,['The Tien Mai'],"In high-dimensional statistics, the Lasso is a cornerstone method for simultaneous variable selection and parameter estimation. However, its reliance on the squared loss function renders it highly sensitive to outliers and heavy-tailed noise, potentially leading to unreliable model selection and biased estimates. To address this limitation, we introduce the Exponential Lasso, a novel robust method that integrates an exponential-type loss function within the Lasso framework. This loss function is designed to achieve a smooth trade-off between statistical efficiency under Gaussian noise and robustness against data contamination. Unlike other methods that cap the influence of large residuals, the exponential loss smoothly redescends, effectively downweighting the impact of extreme outliers while preserving near-quadratic behavior for small errors. We establish theoretical guarantees showing that the Exponential Lasso achieves strong statistical convergence rates, matching the classical Lasso under ideal conditions while maintaining its robustness in the presence of heavy-tailed contamination. Computationally, the estimator is optimized efficiently via a Majorization-Minimization (MM) algorithm that iteratively solves a series of weighted Lasso subproblems. Numerical experiments demonstrate that the proposed method is highly competitive, outperforming the classical Lasso in contaminated settings and maintaining strong performance even under Gaussian noise.   Our method is implemented in the \texttt{R} package \texttt{heavylasso} available on Github: https://github.com/tienmt/heavylasso",arXiv,2025,['stat.ML' 'cs.LG' 'stat.ME'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.15332v1', 'primary_category': 'stat.ML', 'publication_date': None, 'published': '2025-11-19T10:50:46+00:00', 'reference_count': None}",110,1608,1,0,"Exponential Lasso: robust sparse penalization under heavy-tailed noise and outliers with exponential-type loss. In high-dimensional statistics, the Lasso is a cornerstone method for simultaneous variable selection and parameter estimation. However, its reliance on the squared loss function renders it highly sensitive to outliers and heavy-tailed noise, potentially leading to unreliable model selection and biased estimates. To address this limitation, we introduce the Exponential Lasso, a novel robust method that integrates an exponential-type loss function within the Lasso framework. This loss function is designed to achieve a smooth trade-off between statistical efficiency under Gaussian noise and robustness against data contamination. Unlike other methods that cap the influence of large residuals, the exponential loss smoothly redescends, effectively downweighting the impact of extreme outliers while preserving near-quadratic behavior for small errors. We establish theoretical guarantees showing that the Exponential Lasso achieves strong statistical convergence rates, matching the classical Lasso under ideal conditions while maintaining its robustness in the presence of heavy-tailed contamination. Computationally, the estimator is optimized efficiently via a Majorization-Minimization (MM) algorithm that iteratively solves a series of weighted Lasso subproblems. Numerical experiments demonstrate that the proposed method is highly competitive, outperforming the classical Lasso in contaminated settings and maintaining strong performance even under Gaussian noise.   Our method is implemented in the \texttt{R} package \texttt{heavylasso} available on Github: https://github.com/tienmt/heavylasso",3
arxiv_2511.06854v2,Beyond Observations: Reconstruction Error-Guided Irregularly Sampled Time Series Representation Learning,['Jiexi Liu' 'Meng Cao' 'Songcan Chen'],"Irregularly sampled time series (ISTS), characterized by non-uniform time intervals with natural missingness, are prevalent in real-world applications. Existing approaches for ISTS modeling primarily rely on observed values to impute unobserved ones or infer latent dynamics. However, these methods overlook a critical source of learning signal: the reconstruction error inherently produced during model training. Such error implicitly reflects how well a model captures the underlying data structure and can serve as an informative proxy for unobserved values. To exploit this insight, we propose iTimER, a simple yet effective self-supervised pre-training framework for ISTS representation learning. iTimER models the distribution of reconstruction errors over observed values and generates pseudo-observations for unobserved timestamps through a mixup strategy between sampled errors and the last available observations. This transforms unobserved timestamps into noise-aware training targets, enabling meaningful reconstruction signals. A Wasserstein metric aligns reconstruction error distributions between observed and pseudo-observed regions, while a contrastive learning objective enhances the discriminability of learned representations. Extensive experiments on classification, interpolation, and forecasting tasks demonstrate that iTimER consistently outperforms state-of-the-art methods under the ISTS setting.",arXiv,2025,['cs.LG' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.06854v2', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-10T08:53:10+00:00', 'reference_count': None}",104,1422,3,0,"Beyond Observations: Reconstruction Error-Guided Irregularly Sampled Time Series Representation Learning. Irregularly sampled time series (ISTS), characterized by non-uniform time intervals with natural missingness, are prevalent in real-world applications. Existing approaches for ISTS modeling primarily rely on observed values to impute unobserved ones or infer latent dynamics. However, these methods overlook a critical source of learning signal: the reconstruction error inherently produced during model training. Such error implicitly reflects how well a model captures the underlying data structure and can serve as an informative proxy for unobserved values. To exploit this insight, we propose iTimER, a simple yet effective self-supervised pre-training framework for ISTS representation learning. iTimER models the distribution of reconstruction errors over observed values and generates pseudo-observations for unobserved timestamps through a mixup strategy between sampled errors and the last available observations. This transforms unobserved timestamps into noise-aware training targets, enabling meaningful reconstruction signals. A Wasserstein metric aligns reconstruction error distributions between observed and pseudo-observed regions, while a contrastive learning objective enhances the discriminability of learned representations. Extensive experiments on classification, interpolation, and forecasting tasks demonstrate that iTimER consistently outperforms state-of-the-art methods under the ISTS setting.",3
arxiv_2511.12234v1,A Review of Statistical and Machine Learning Approaches for Coral Bleaching Assessment,['Soham Sarkar' 'Arnab Hazra'],"Coral bleaching is a major concern for marine ecosystems; more than half of the world's coral reefs have either bleached or died over the past three decades. Increasing sea surface temperatures, along with various spatiotemporal environmental factors, are considered the primary reasons behind coral bleaching. The statistical and machine learning communities have focused on multiple aspects of the environment in detail. However, the literature on various stochastic modeling approaches for assessing coral bleaching is extremely scarce. Data-driven strategies are crucial for effective reef management, and this review article provides an overview of existing statistical and machine learning methods for assessing coral bleaching. Statistical frameworks, including simple regression models, generalized linear models, generalized additive models, Bayesian regression models, spatiotemporal models, and resilience indicators, such as Fisher's Information and Variance Index, are commonly used to explore how different environmental stressors influence coral bleaching. On the other hand, machine learning methods, including random forests, decision trees, support vector machines, and spatial operators, are more popular for detecting nonlinear relationships, analyzing high-dimensional data, and allowing integration of heterogeneous data from diverse sources. In addition to summarizing these models, we also discuss potential data-driven future research directions, with a focus on constructing statistical and machine learning models in specific contexts related to coral bleaching.",arXiv,2025,['stat.AP' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.12234v1', 'primary_category': 'stat.AP', 'publication_date': None, 'published': '2025-11-15T14:22:56+00:00', 'reference_count': None}",86,1589,2,0,"A Review of Statistical and Machine Learning Approaches for Coral Bleaching Assessment. Coral bleaching is a major concern for marine ecosystems; more than half of the world's coral reefs have either bleached or died over the past three decades. Increasing sea surface temperatures, along with various spatiotemporal environmental factors, are considered the primary reasons behind coral bleaching. The statistical and machine learning communities have focused on multiple aspects of the environment in detail. However, the literature on various stochastic modeling approaches for assessing coral bleaching is extremely scarce. Data-driven strategies are crucial for effective reef management, and this review article provides an overview of existing statistical and machine learning methods for assessing coral bleaching. Statistical frameworks, including simple regression models, generalized linear models, generalized additive models, Bayesian regression models, spatiotemporal models, and resilience indicators, such as Fisher's Information and Variance Index, are commonly used to explore how different environmental stressors influence coral bleaching. On the other hand, machine learning methods, including random forests, decision trees, support vector machines, and spatial operators, are more popular for detecting nonlinear relationships, analyzing high-dimensional data, and allowing integration of heterogeneous data from diverse sources. In addition to summarizing these models, we also discuss potential data-driven future research directions, with a focus on constructing statistical and machine learning models in specific contexts related to coral bleaching.",3
s2_7260442ef9c0448f07ce3803efd49cebaffcebe9,DeepSeek LLM: Scaling Open-Source Language Models with Longtermism,"['DeepSeek-AI Xiao Bi' 'Deli Chen' 'Guanting Chen' 'Shanhuang Chen'
 'Damai Dai' 'C. Deng' 'Honghui Ding' 'Kai Dong' 'Qiushi Du' 'Zhe Fu'
 'Huazuo Gao' 'Kaige Gao' 'Wenjun Gao' 'Ruiqi Ge' 'Kang Guan' 'Daya Guo'
 'Jianzhong Guo' 'Guangbo Hao' 'Zhewen Hao' 'Ying He' 'Wen-Hui Hu'
 'Panpan Huang' 'Erhang Li' 'Guowei Li' 'Jiashi Li' 'Yao Li' 'Y. K. Li'
 'W. Liang' 'Fangyun Lin' 'A. Liu' 'Bo Liu (Benjamin Liu)' 'Wen Liu'
 'Xiaodong Liu' 'Xin Liu' 'Yiyuan Liu' 'Haoyu Lu' 'Shanghao Lu' 'Fuli Luo'
 'Shirong Ma' 'X. Nie' 'Tian Pei' 'Yishi Piao' 'Junjie Qiu' 'Hui Qu'
 'Tongzheng Ren' 'Z. Ren' 'C. Ruan' 'Zhangli Sha' 'Zhihong Shao'
 'Jun-Mei Song' 'Xuecheng Su' 'Jingxiang Sun' 'Yaofeng Sun' 'Min Tang'
 'Bing-Li Wang' 'Peiyi Wang' 'Shiyu Wang' 'Yaohui Wang' 'Yongji Wang'
 'Tong Wu' 'Yu Wu' 'Xin Xie' 'Zhenda Xie' 'Ziwei Xie' 'Yi Xiong'
 'Hanwei Xu' 'R. X. Xu' 'Yanhong Xu' 'Dejian Yang' 'Yu-mei You'
 'Shuiping Yu' 'Xin-yuan Yu' 'Bo Zhang' 'Haowei Zhang' 'Lecong Zhang'
 'Liyue Zhang' 'Mingchuan Zhang' 'Minghu Zhang' 'Wentao Zhang'
 'Yichao Zhang' 'Chenggang Zhao' 'Yao Zhao' 'Shangyan Zhou'
 'Shunfeng Zhou' 'Qihao Zhu' 'Yuheng Zou']","The rapid development of open-source large language models (LLMs) has been truly remarkable. However, the scaling law described in previous literature presents varying conclusions, which casts a dark cloud over scaling LLMs. We delve into the study of scaling laws and present our distinctive findings that facilitate scaling of large scale models in two commonly used open-source configurations, 7B and 67B. Guided by the scaling laws, we introduce DeepSeek LLM, a project dedicated to advancing open-source language models with a long-term perspective. To support the pre-training phase, we have developed a dataset that currently consists of 2 trillion tokens and is continuously expanding. We further conduct supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) on DeepSeek LLM Base models, resulting in the creation of DeepSeek Chat models. Our evaluation results demonstrate that DeepSeek LLM 67B surpasses LLaMA-2 70B on various benchmarks, particularly in the domains of code, mathematics, and reasoning. Furthermore, open-ended evaluations reveal that DeepSeek LLM 67B Chat exhibits superior performance compared to GPT-3.5.",arXiv.org,2024,['Computer Science'],s2orc,"{'citation_count': 561.0, 'external_ids': {'ACL': None, 'ArXiv': '2401.02954', 'CorpusId': 266818336.0, 'DBLP': 'journals/corr/abs-2401-02954', 'DOI': None, 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2024-01-05', 'published': None, 'reference_count': 71.0}",66,1150,86,0,"DeepSeek LLM: Scaling Open-Source Language Models with Longtermism. The rapid development of open-source large language models (LLMs) has been truly remarkable. However, the scaling law described in previous literature presents varying conclusions, which casts a dark cloud over scaling LLMs. We delve into the study of scaling laws and present our distinctive findings that facilitate scaling of large scale models in two commonly used open-source configurations, 7B and 67B. Guided by the scaling laws, we introduce DeepSeek LLM, a project dedicated to advancing open-source language models with a long-term perspective. To support the pre-training phase, we have developed a dataset that currently consists of 2 trillion tokens and is continuously expanding. We further conduct supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) on DeepSeek LLM Base models, resulting in the creation of DeepSeek Chat models. Our evaluation results demonstrate that DeepSeek LLM 67B surpasses LLaMA-2 70B on various benchmarks, particularly in the domains of code, mathematics, and reasoning. Furthermore, open-ended evaluations reveal that DeepSeek LLM 67B Chat exhibits superior performance compared to GPT-3.5.",2
s2_9cbd838531b084bd402dec4dffdcb34d5d5e7f52,"POSTER: TRIDENT -- A Three-Tier Privacy-Preserving Propaganda Detection Model in Mobile Networks using Transformers, Adversarial Learning, and Differential Privacy","['Al Nahian Bin Emran' 'Dhiman Goswami' 'Md Hasan Ullah Sadi'
 'Sanchari Das']","The proliferation of propaganda on mobile platforms raises critical concerns around detection accuracy and user privacy. To address this, we propose TRIDENT -a three-tier propaganda detection model implementing transformers, adversarial learning, and differential privacy which integrates syntactic obfuscation and label perturbation to mitigate privacy leakage while maintaining propaganda detection accuracy. TRIDENT leverages multilingual back-translation to introduce semantic variance, character-level noise, and entity obfuscation for differential privacy enforcement, and combines these techniques into a unified defense mechanism. Using a binary propaganda classification dataset, baseline transformer models (BERT, GPT-2) we achieved F1 scores of 0.89 and 0.90. Applying TRIDENT's third-tier defense yields a reduced but effective cumulative F1 of 0.83, demonstrating strong privacy protection across mobile ML deployments with minimal degradation.",Wireless Network Security,2025,['Computer Science'],s2orc,"{'citation_count': 0.0, 'external_ids': {'ACL': None, 'ArXiv': '2506.05421', 'CorpusId': 279244872.0, 'DBLP': 'conf/wisec/EmranGSD25', 'DOI': '10.1145/3734477.3736148', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2025-06-05', 'published': None, 'reference_count': 5.0}",163,957,4,0,"POSTER: TRIDENT -- A Three-Tier Privacy-Preserving Propaganda Detection Model in Mobile Networks using Transformers, Adversarial Learning, and Differential Privacy. The proliferation of propaganda on mobile platforms raises critical concerns around detection accuracy and user privacy. To address this, we propose TRIDENT -a three-tier propaganda detection model implementing transformers, adversarial learning, and differential privacy which integrates syntactic obfuscation and label perturbation to mitigate privacy leakage while maintaining propaganda detection accuracy. TRIDENT leverages multilingual back-translation to introduce semantic variance, character-level noise, and entity obfuscation for differential privacy enforcement, and combines these techniques into a unified defense mechanism. Using a binary propaganda classification dataset, baseline transformer models (BERT, GPT-2) we achieved F1 scores of 0.89 and 0.90. Applying TRIDENT's third-tier defense yields a reduced but effective cumulative F1 of 0.83, demonstrating strong privacy protection across mobile ML deployments with minimal degradation.",2
arxiv_2511.14683v1,Quadratic Term Correction on Heaps' Law,['Oscar Fontanelli' 'Wentian Li'],"Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a linear and quadratic term consistently lead to a linear coefficient of slightly larger than 1, and a quadratic coefficient around -0.02. Using the ``random drawing colored ball from the bag with replacement"" model, we have shown that the curvature of the log-log scale is identical to a ``pseudo-variance"" which is negative. Although a pseudo-variance calculation may encounter numeric instability when the number of tokens is large, due to the large values of pseudo-weights, this formalism provides a rough estimation of the curvature when the number of tokens is small.",arXiv,2025,['cs.CL'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14683v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-18T17:22:00+00:00', 'reference_count': None}",39,1172,2,0,"Quadratic Term Correction on Heaps' Law. Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a linear and quadratic term consistently lead to a linear coefficient of slightly larger than 1, and a quadratic coefficient around -0.02. Using the ``random drawing colored ball from the bag with replacement"" model, we have shown that the curvature of the log-log scale is identical to a ``pseudo-variance"" which is negative. Although a pseudo-variance calculation may encounter numeric instability when the number of tokens is large, due to the large values of pseudo-weights, this formalism provides a rough estimation of the curvature when the number of tokens is small.",4
s2_4ce2ceb4ee975b032578e8816cb8f50a9984c76e,"Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition",['Xianrui Zheng' 'Chao Zhang' 'P. Woodland'],"Language models (LMs) pre-trained on massive amounts of text, in particular bidirectional encoder representations from Transformers (BERT), generative pre-training (GPT), and GPT-2, have become a key technology for many natural language processing tasks. In this paper, we present results using fine-tuned GPT, GPT-2, and their combination for automatic speech recognition (ASR). Unlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct product of the output probabilities is no longer a valid language prior probability. A conversion method is proposed to compute the correct language prior probability based on bidirectional LM outputs in a mathematically exact way. Experimental results on the widely used AMI and Switchboard ASR tasks showed that the combination of the fine-tuned GPT and GPT-2 outperformed the combination of three neural LMs with different architectures trained from scratch on the in-domain text by up to a 12% relative word error rate reduction (WERR). Furthermore, on the AMI corpus, the proposed conversion for language prior probabilities enables BERT to obtain an extra 3% relative WERR, and the combination of BERT, GPT and GPT-2 results in further improvements.",Automatic Speech Recognition & Understanding,2021,['Computer Science' 'Engineering'],s2orc,"{'citation_count': 61.0, 'external_ids': {'ACL': None, 'ArXiv': '2108.07789', 'CorpusId': 237142586.0, 'DBLP': 'journals/corr/abs-2108-07789', 'DOI': '10.1109/ASRU51503.2021.9688232', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2021-07-29', 'published': None, 'reference_count': 49.0}",67,1210,3,0,"Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition. Language models (LMs) pre-trained on massive amounts of text, in particular bidirectional encoder representations from Transformers (BERT), generative pre-training (GPT), and GPT-2, have become a key technology for many natural language processing tasks. In this paper, we present results using fine-tuned GPT, GPT-2, and their combination for automatic speech recognition (ASR). Unlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct product of the output probabilities is no longer a valid language prior probability. A conversion method is proposed to compute the correct language prior probability based on bidirectional LM outputs in a mathematically exact way. Experimental results on the widely used AMI and Switchboard ASR tasks showed that the combination of the fine-tuned GPT and GPT-2 outperformed the combination of three neural LMs with different architectures trained from scratch on the in-domain text by up to a 12% relative word error rate reduction (WERR). Furthermore, on the AMI corpus, the proposed conversion for language prior probabilities enables BERT to obtain an extra 3% relative WERR, and the combination of BERT, GPT and GPT-2 results in further improvements.",4
s2_b611c501269224702d1a9942c8600a31ec66ab28,ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning,['Ahmed Masry' 'Do Xuan Long' 'J. Tan' 'Shafiq R. Joty' 'Enamul Hoque'],"Charts are very popular for analyzing data. When exploring charts, people often ask a variety of complex reasoning questions that involve several logical and arithmetic operations. They also commonly refer to visual features of a chart in their questions. However, most existing datasets do not focus on such complex reasoning questions as their questions are template-based and answers come from a fixed-vocabulary. In this work, we present a large-scale benchmark covering 9.6K human-written questions as well as 23.1K questions generated from human-written chart summaries. To address the unique challenges in our benchmark involving visual and logical reasoning over charts, we present two transformer-based models that combine visual features and the data table of the chart in a unified way to answer questions. While our models achieve the state-of-the-art results on the previous datasets as well as on our benchmark, the evaluation also reveals several challenges in answering complex reasoning questions.",Findings,2022,['Computer Science'],s2orc,"{'citation_count': 1009.0, 'external_ids': {'ACL': '2022.findings-acl.177', 'ArXiv': '2203.10244', 'CorpusId': 247593713.0, 'DBLP': 'conf/acl/MasryLTJH22', 'DOI': '10.48550/arXiv.2203.10244', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2022-03-19', 'published': None, 'reference_count': 43.0}",90,1014,5,0,"ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning. Charts are very popular for analyzing data. When exploring charts, people often ask a variety of complex reasoning questions that involve several logical and arithmetic operations. They also commonly refer to visual features of a chart in their questions. However, most existing datasets do not focus on such complex reasoning questions as their questions are template-based and answers come from a fixed-vocabulary. In this work, we present a large-scale benchmark covering 9.6K human-written questions as well as 23.1K questions generated from human-written chart summaries. To address the unique challenges in our benchmark involving visual and logical reasoning over charts, we present two transformer-based models that combine visual features and the data table of the chart in a unified way to answer questions. While our models achieve the state-of-the-art results on the previous datasets as well as on our benchmark, the evaluation also reveals several challenges in answering complex reasoning questions.",1
s2_d4e9bf1d5fab52698a3aa48c65b098ea327deea6,CTRLsum: Towards Generic Controllable Text Summarization,"['Junxian He' 'Wojciech Kryscinski' 'Bryan McCann' 'Nazneen Rajani'
 'Caiming Xiong']","Current summarization systems yield generic summaries that are disconnected from users’ preferences and expectations. To address this limitation, we present CTRLsum, a generic framework to control generated summaries through a set of keywords. During training keywords are extracted automatically without requiring additional human annotations. At test time CTRLsum features a control function to map control signal to keywords; through engineering the control function, the same trained model is able to be applied to control summaries on various dimensions, while neither affecting the model training process nor the pretrained models. We additionally explore the combination of keywords and text prompts for more control tasks. Experiments demonstrate the effectiveness of CTRLsum on three domains of summarization datasets and five control tasks: (1) entity-centric and (2) length-controllable summarization, (3) contribution summarization on scientific papers, (4) invention purpose summarization on patent filings, and (5) question-guided summarization on news articles. Moreover, when used in a standard, unconstrained summarization setting, CTRLsum is comparable or better than strong pretrained systems.",Conference on Empirical Methods in Natural Language Processing,2020,['Computer Science'],s2orc,"{'citation_count': 151.0, 'external_ids': {'ACL': '2022.emnlp-main.396', 'ArXiv': '2012.04281', 'CorpusId': 227745074.0, 'DBLP': 'conf/emnlp/HeKMRX22', 'DOI': '10.18653/v1/2022.emnlp-main.396', 'MAG': '3111372071', 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2020-12-08', 'published': None, 'reference_count': 93.0}",56,1212,5,0,"CTRLsum: Towards Generic Controllable Text Summarization. Current summarization systems yield generic summaries that are disconnected from users’ preferences and expectations. To address this limitation, we present CTRLsum, a generic framework to control generated summaries through a set of keywords. During training keywords are extracted automatically without requiring additional human annotations. At test time CTRLsum features a control function to map control signal to keywords; through engineering the control function, the same trained model is able to be applied to control summaries on various dimensions, while neither affecting the model training process nor the pretrained models. We additionally explore the combination of keywords and text prompts for more control tasks. Experiments demonstrate the effectiveness of CTRLsum on three domains of summarization datasets and five control tasks: (1) entity-centric and (2) length-controllable summarization, (3) contribution summarization on scientific papers, (4) invention purpose summarization on patent filings, and (5) question-guided summarization on news articles. Moreover, when used in a standard, unconstrained summarization setting, CTRLsum is comparable or better than strong pretrained systems.",4
s2_11b6d1fee0f47a8f9f892ab0d86f370c449097aa,FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization,['Esin Durmus' 'He He' 'Mona T. Diab'],"Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA, which leverages recent advances in reading comprehension. Given question-answer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.",Annual Meeting of the Association for Computational Linguistics,2020,['Computer Science'],s2orc,"{'citation_count': 427.0, 'external_ids': {'ACL': '2020.acl-main.454', 'ArXiv': '2005.03754', 'CorpusId': 218571335.0, 'DBLP': 'journals/corr/abs-2005-03754', 'DOI': '10.18653/V1/2020.ACL-MAIN.454', 'MAG': '3099766584', 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2020-05-07', 'published': None, 'reference_count': 56.0}",104,1131,3,0,"FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization. Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA, which leverages recent advances in reading comprehension. Given question-answer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.",1
s2_16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277,Time-LLM: Time Series Forecasting by Reprogramming Large Language Models,"['Ming Jin' 'Shiyu Wang' 'Lintao Ma' 'Zhixuan Chu' 'James Y. Zhang'
 'X. Shi' 'Pin-Yu Chen' 'Yuxuan Liang' 'Yuan-Fang Li' 'Shirui Pan'
 'Qingsong Wen']","Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.",International Conference on Learning Representations,2023,['Computer Science'],s2orc,"{'citation_count': 642.0, 'external_ids': {'ACL': None, 'ArXiv': '2310.01728', 'CorpusId': 263609325.0, 'DBLP': 'journals/corr/abs-2310-01728', 'DOI': '10.48550/arXiv.2310.01728', 'MAG': None, 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2023-10-03', 'published': None, 'reference_count': 63.0}",72,1645,11,0,"Time-LLM: Time Series Forecasting by Reprogramming Large Language Models. Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.",4
arxiv_2511.14981v1,Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation,['Nicholas Cooper' 'Lijun Chen' 'Sailesh Dwivedy' 'Danna Gurari'],"Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at https://github.com/Thegolfingocto/KD_wo_CE.",arXiv,2025,['cs.CV' 'cs.AI' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.14981v1', 'primary_category': 'cs.CV', 'publication_date': None, 'published': '2025-11-18T23:50:31+00:00', 'reference_count': None}",76,1104,4,0,"Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation. Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at https://github.com/Thegolfingocto/KD_wo_CE.",4
arxiv_2511.11262v1,Discovering Meaningful Units with Visually Grounded Semantics from Image Captions,['Melika Behjati' 'James Henderson'],"Fine-grained knowledge is crucial for vision-language models to obtain a better understanding of the real world. While there has been work trying to acquire this kind of knowledge in the space of vision and language, it has mostly focused on aligning the image patches with the tokens on the language side. However, image patches do not have any meaning to the human eye, and individual tokens do not necessarily carry groundable information in the image. It is groups of tokens which describe different aspects of the scene. In this work, we propose a model which groups the caption tokens as part of its architecture in order to capture a fine-grained representation of the language. We expect our representations to be at the level of objects present in the image, and therefore align our representations with the output of an image encoder trained to discover objects. We show that by learning to group the tokens, the vision-language model has a better fine-grained understanding of vision and language. In addition, the token groups that our model discovers are highly similar to groundable phrases in text, both qualitatively and quantitatively.",arXiv,2025,['cs.CV' 'cs.CL'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.11262v1', 'primary_category': 'cs.CV', 'publication_date': None, 'published': '2025-11-14T12:56:18+00:00', 'reference_count': None}",81,1152,2,0,"Discovering Meaningful Units with Visually Grounded Semantics from Image Captions. Fine-grained knowledge is crucial for vision-language models to obtain a better understanding of the real world. While there has been work trying to acquire this kind of knowledge in the space of vision and language, it has mostly focused on aligning the image patches with the tokens on the language side. However, image patches do not have any meaning to the human eye, and individual tokens do not necessarily carry groundable information in the image. It is groups of tokens which describe different aspects of the scene. In this work, we propose a model which groups the caption tokens as part of its architecture in order to capture a fine-grained representation of the language. We expect our representations to be at the level of objects present in the image, and therefore align our representations with the output of an image encoder trained to discover objects. We show that by learning to group the tokens, the vision-language model has a better fine-grained understanding of vision and language. In addition, the token groups that our model discovers are highly similar to groundable phrases in text, both qualitatively and quantitatively.",4
s2_83a820fe19944a7621238b8cfcc0b8a0cbc0f4b6,TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages,"['J. Clark' 'Eunsol Choi' 'Michael Collins' 'Dan Garrette'
 'T. Kwiatkowski' 'Vitaly Nikolaev' 'J. Palomaki']","Abstract Confidently making progress on multilingual modeling requires challenging, trustworthy evaluations. We present TyDi QA—a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs. The languages of TyDi QA are diverse with regard to their typology—the set of linguistic features each language expresses—such that we expect models performing well on this set to generalize across a large number of the world’s languages. We present a quantitative analysis of the data quality and example-level qualitative linguistic analyses of observed language phenomena that would not be found in English-only corpora. To provide a realistic information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but don’t know the answer yet, and the data is collected directly in each language without the use of translation.",Transactions of the Association for Computational Linguistics,2020,['Computer Science'],s2orc,"{'citation_count': 678.0, 'external_ids': {'ACL': None, 'ArXiv': '2003.05002', 'CorpusId': 212657414.0, 'DBLP': 'journals/tacl/ClarkPNCGCK20', 'DOI': '10.1162/tacl_a_00317', 'MAG': '3045462440', 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2020-03-10', 'published': None, 'reference_count': 84.0}",98,908,7,0,"TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages. Abstract Confidently making progress on multilingual modeling requires challenging, trustworthy evaluations. We present TyDi QA—a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs. The languages of TyDi QA are diverse with regard to their typology—the set of linguistic features each language expresses—such that we expect models performing well on this set to generalize across a large number of the world’s languages. We present a quantitative analysis of the data quality and example-level qualitative linguistic analyses of observed language phenomena that would not be found in English-only corpora. To provide a realistic information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but don’t know the answer yet, and the data is collected directly in each language without the use of translation.",1
arxiv_2511.15409v1,Proximal Approximate Inference in State-Space Models,['Hany Abdulsamad' 'Ángel F. García-Fernández' 'Simo Särkkä'],"We present a class of algorithms for state estimation in nonlinear, non-Gaussian state-space models. Our approach is based on a variational Lagrangian formulation that casts Bayesian inference as a sequence of entropic trust-region updates subject to dynamic constraints. This framework gives rise to a family of forward-backward algorithms, whose structure is determined by the chosen factorization of the variational posterior. By focusing on Gauss--Markov approximations, we derive recursive schemes with favorable computational complexity. For general nonlinear, non-Gaussian models we close the recursions using generalized statistical linear regression and Fourier--Hermite moment matching.",arXiv,2025,['cs.LG' 'stat.ME'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.15409v1', 'primary_category': 'cs.LG', 'publication_date': None, 'published': '2025-11-19T13:06:08+00:00', 'reference_count': None}",52,696,3,0,"Proximal Approximate Inference in State-Space Models. We present a class of algorithms for state estimation in nonlinear, non-Gaussian state-space models. Our approach is based on a variational Lagrangian formulation that casts Bayesian inference as a sequence of entropic trust-region updates subject to dynamic constraints. This framework gives rise to a family of forward-backward algorithms, whose structure is determined by the chosen factorization of the variational posterior. By focusing on Gauss--Markov approximations, we derive recursive schemes with favorable computational complexity. For general nonlinear, non-Gaussian models we close the recursions using generalized statistical linear regression and Fourier--Hermite moment matching.",0
arxiv_2511.10899v1,From Proof to Program: Characterizing Tool-Induced Reasoning Hallucinations in Large Language Models,['Farima Fatahi Bayat' 'Pouya Pezeshkpour' 'Estevam Hruschka'],"Tool-augmented Language Models (TaLMs) can invoke external tools to solve problems beyond their parametric capacity. However, it remains unclear whether these tool-enabled gains reflect trustworthy reasoning. Focusing on the Code Interpreter tool, we show that even when tools are selected and executed correctly, TaLMs treat tool outputs as substitutes for reasoning, producing solutions that appear correct but lack coherent justification. We term this failure mode Tool-Induced Myopia (TIM), and study it using PYMATH, a benchmark of 1,679 competition-level mathematical problems for which Python code is helpful but not sufficient. We further develop a multi-dimensional evaluation suite to quantify reasoning degradation in TaLMs relative to their non-tool counterparts. Our findings reveal that while TaLMs achieve up to a 19.3 percentage point gain in final-answer accuracy, their reasoning behavior consistently deteriorates (e.g., non-tool LLMs win up to 41.5% more often in pairwise comparisons of the reasoning process). This degradation intensifies with tool use; the more frequently a model invokes tools, the less coherent its reasoning becomes. Moreover, tool use shifts errors from arithmetic mistakes toward global reasoning failures (logic, assumption, creativity); with TIM present in ~55% of high-risk cases. Finally, we propose a preference-optimization-based framework that realigns TaLMs to use tools as assistive evidence, improving both final-answer accuracy and reasoning depth under tool use. Codes and data are available at: https://github.com/megagonlabs/TIM.",arXiv,2025,['cs.CL' 'cs.LO' 'cs.SE'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.10899v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-14T02:21:34+00:00', 'reference_count': None}",100,1588,3,0,"From Proof to Program: Characterizing Tool-Induced Reasoning Hallucinations in Large Language Models. Tool-augmented Language Models (TaLMs) can invoke external tools to solve problems beyond their parametric capacity. However, it remains unclear whether these tool-enabled gains reflect trustworthy reasoning. Focusing on the Code Interpreter tool, we show that even when tools are selected and executed correctly, TaLMs treat tool outputs as substitutes for reasoning, producing solutions that appear correct but lack coherent justification. We term this failure mode Tool-Induced Myopia (TIM), and study it using PYMATH, a benchmark of 1,679 competition-level mathematical problems for which Python code is helpful but not sufficient. We further develop a multi-dimensional evaluation suite to quantify reasoning degradation in TaLMs relative to their non-tool counterparts. Our findings reveal that while TaLMs achieve up to a 19.3 percentage point gain in final-answer accuracy, their reasoning behavior consistently deteriorates (e.g., non-tool LLMs win up to 41.5% more often in pairwise comparisons of the reasoning process). This degradation intensifies with tool use; the more frequently a model invokes tools, the less coherent its reasoning becomes. Moreover, tool use shifts errors from arithmetic mistakes toward global reasoning failures (logic, assumption, creativity); with TIM present in ~55% of high-risk cases. Finally, we propose a preference-optimization-based framework that realigns TaLMs to use tools as assistive evidence, improving both final-answer accuracy and reasoning depth under tool use. Codes and data are available at: https://github.com/megagonlabs/TIM.",1
arxiv_2511.05352v1,A Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model: Maximum Likelihood Estimation and Fisher Information,"['Carlos Llosa-Vite' 'Daniel M. Dunlavy' 'Richard B. Lehoucq'
 'Oscar López' 'Arvind Prasadan']","We establish parameter inference for the Poisson canonical polyadic (PCP) tensor model through a latent-variable formulation. Our approach exploits the observation that any random PCP tensor can be derived by marginalizing an unobservable random tensor of one dimension larger. The loglikelihood of this larger dimensional tensor, referred to as the ""complete"" loglikelihood, is comprised of multiple rank one PCP loglikelihoods. Using this methodology, we first derive non-iterative maximum likelihood estimators for the PCP model and demonstrate that several existing algorithms for fitting non-negative matrix and tensor factorizations are Expectation-Maximization algorithms. Next, we derive the observed and expected Fisher information matrices for the PCP model. The Fisher information provides us crucial insights into the well-posedness of the tensor model, such as the role that tensor rank plays in identifiability and indeterminacy. For the special case of rank one PCP models, we demonstrate that these results are greatly simplified.",arXiv,2025,['math.ST' 'math.NA' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.05352v1', 'primary_category': 'math.ST', 'publication_date': None, 'published': '2025-11-07T15:45:13+00:00', 'reference_count': None}",130,1046,5,0,"A Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model: Maximum Likelihood Estimation and Fisher Information. We establish parameter inference for the Poisson canonical polyadic (PCP) tensor model through a latent-variable formulation. Our approach exploits the observation that any random PCP tensor can be derived by marginalizing an unobservable random tensor of one dimension larger. The loglikelihood of this larger dimensional tensor, referred to as the ""complete"" loglikelihood, is comprised of multiple rank one PCP loglikelihoods. Using this methodology, we first derive non-iterative maximum likelihood estimators for the PCP model and demonstrate that several existing algorithms for fitting non-negative matrix and tensor factorizations are Expectation-Maximization algorithms. Next, we derive the observed and expected Fisher information matrices for the PCP model. The Fisher information provides us crucial insights into the well-posedness of the tensor model, such as the role that tensor rank plays in identifiability and indeterminacy. For the special case of rank one PCP models, we demonstrate that these results are greatly simplified.",3
arxiv_2511.06189v1,Counterfactual Forecasting For Panel Data,['Navonil Deb' 'Raaz Dwivedi' 'Sumanta Basu'],"We address the challenge of forecasting counterfactual outcomes in a panel data with missing entries and temporally dependent latent factors -- a common scenario in causal inference, where estimating unobserved potential outcomes ahead of time is essential. We propose Forecasting Counterfactuals under Stochastic Dynamics (FOCUS), a method that extends traditional matrix completion methods by leveraging time series dynamics of the factors, thereby enhancing the prediction accuracy of future counterfactuals. Building upon a PCA estimator, our method accommodates both stochastic and deterministic components within the factors, and provides a flexible framework for various applications. In case of stationary autoregressive factors and under standard conditions, we derive error bounds and establish asymptotic normality of our estimator. Empirical evaluations demonstrate that our method outperforms existing benchmarks when the latent factors have an autoregressive component. We illustrate FOCUS results on HeartSteps, a mobile health study, illustrating its effectiveness in forecasting step counts for users receiving activity prompts, thereby leveraging temporal patterns in user behavior.",arXiv,2025,['stat.ME' 'math.ST' 'stat.ML'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.06189v1', 'primary_category': 'stat.ME', 'publication_date': None, 'published': '2025-11-09T02:25:49+00:00', 'reference_count': None}",41,1200,3,0,"Counterfactual Forecasting For Panel Data. We address the challenge of forecasting counterfactual outcomes in a panel data with missing entries and temporally dependent latent factors -- a common scenario in causal inference, where estimating unobserved potential outcomes ahead of time is essential. We propose Forecasting Counterfactuals under Stochastic Dynamics (FOCUS), a method that extends traditional matrix completion methods by leveraging time series dynamics of the factors, thereby enhancing the prediction accuracy of future counterfactuals. Building upon a PCA estimator, our method accommodates both stochastic and deterministic components within the factors, and provides a flexible framework for various applications. In case of stationary autoregressive factors and under standard conditions, we derive error bounds and establish asymptotic normality of our estimator. Empirical evaluations demonstrate that our method outperforms existing benchmarks when the latent factors have an autoregressive component. We illustrate FOCUS results on HeartSteps, a mobile health study, illustrating its effectiveness in forecasting step counts for users receiving activity prompts, thereby leveraging temporal patterns in user behavior.",3
s2_97ad70a9fa3f99adf18030e5e38ebe3d90daa2db,VQA: Visual Question Answering,"['Aishwarya Agrawal' 'Jiasen Lu' 'Stanislaw Antol' 'Margaret Mitchell'
 'C. L. Zitnick' 'Devi Parikh' 'Dhruv Batra']","We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing ∼\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim $$\end{document}0.25 M images, ∼\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim $$\end{document}0.76 M questions, and ∼\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim $$\end{document}10 M answers (www.visualqa.org), and discuss the information it provides. Numerous baselines and methods for VQA are provided and compared with human performance. Our VQA demo is available on CloudCV (http://cloudcv.org/vqa).",International Journal of Computer Vision,2015,['Computer Science'],s2orc,"{'citation_count': 5969.0, 'external_ids': {'ACL': None, 'ArXiv': '1505.00468', 'CorpusId': 3180429.0, 'DBLP': 'journals/corr/AntolALMBZP15', 'DOI': '10.1007/s11263-016-0966-6', 'MAG': '1933349210', 'PubMed': None, 'PubMedCentral': None}, 'pdf_url': None, 'primary_category': None, 'publication_date': '2015-05-03', 'published': None, 'reference_count': 73.0}",30,1846,7,0,"VQA: Visual Question Answering. We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing ∼\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim $$\end{document}0.25 M images, ∼\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim $$\end{document}0.76 M questions, and ∼\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim $$\end{document}10 M answers (www.visualqa.org), and discuss the information it provides. Numerous baselines and methods for VQA are provided and compared with human performance. Our VQA demo is available on CloudCV (http://cloudcv.org/vqa).",1
arxiv_2511.10824v1,Neural Local Wasserstein Regression,['Inga Girshfeld' 'Xiaohui Chen'],"We study the estimation problem of distribution-on-distribution regression, where both predictors and responses are probability measures. Existing approaches typically rely on a global optimal transport map or tangent-space linearization, which can be restrictive in approximation capacity and distort geometry in multivariate underlying domains. In this paper, we propose the \emph{Neural Local Wasserstein Regression}, a flexible nonparametric framework that models regression through locally defined transport maps in Wasserstein space. Our method builds on the analogy with classical kernel regression: kernel weights based on the 2-Wasserstein distance localize estimators around reference measures, while neural networks parameterize transport operators that adapt flexibly to complex data geometries. This localized perspective broadens the class of admissible transformations and avoids the limitations of global map assumptions and linearization structures. We develop a practical training procedure using DeepSets-style architectures and Sinkhorn-approximated losses, combined with a greedy reference selection strategy for scalability. Through synthetic experiments on Gaussian and mixture models, as well as distributional prediction tasks on MNIST, we demonstrate that our approach effectively captures nonlinear and high-dimensional distributional relationships that elude existing methods.",arXiv,2025,['stat.ML' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.10824v1', 'primary_category': 'stat.ML', 'publication_date': None, 'published': '2025-11-13T21:54:18+00:00', 'reference_count': None}",35,1404,2,0,"Neural Local Wasserstein Regression. We study the estimation problem of distribution-on-distribution regression, where both predictors and responses are probability measures. Existing approaches typically rely on a global optimal transport map or tangent-space linearization, which can be restrictive in approximation capacity and distort geometry in multivariate underlying domains. In this paper, we propose the \emph{Neural Local Wasserstein Regression}, a flexible nonparametric framework that models regression through locally defined transport maps in Wasserstein space. Our method builds on the analogy with classical kernel regression: kernel weights based on the 2-Wasserstein distance localize estimators around reference measures, while neural networks parameterize transport operators that adapt flexibly to complex data geometries. This localized perspective broadens the class of admissible transformations and avoids the limitations of global map assumptions and linearization structures. We develop a practical training procedure using DeepSets-style architectures and Sinkhorn-approximated losses, combined with a greedy reference selection strategy for scalability. Through synthetic experiments on Gaussian and mixture models, as well as distributional prediction tasks on MNIST, we demonstrate that our approach effectively captures nonlinear and high-dimensional distributional relationships that elude existing methods.",3
arxiv_2511.16416v1,"Classification of worldwide news articles by perceived quality, 2018-2024",['Connor McElroy' 'Thiago E. A. de Oliveira' 'Chris Brogly'],"This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.",arXiv,2025,['cs.CL' 'cs.LG'],arxiv,"{'citation_count': None, 'external_ids': None, 'pdf_url': 'https://arxiv.org/pdf/2511.16416v1', 'primary_category': 'cs.CL', 'publication_date': None, 'published': '2025-11-20T14:41:41+00:00', 'reference_count': None}",73,1305,3,0,"Classification of worldwide news articles by perceived quality, 2018-2024. This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.",4
