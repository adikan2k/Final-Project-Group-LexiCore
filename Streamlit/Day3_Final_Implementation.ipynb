{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13968613,"sourceType":"datasetVersion","datasetId":8904831}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üìö Scholarly Topic Navigator - Day 3 Complete Pipeline\n\n## Integration, UI, and Explainability (FIXED VERSION)\n\n**Team:** Aditya, Trisha, Pramod\n\n---\n\n### Day 3 Objectives:\n1. **Load Day 2 Components** - Data, Embeddings\n2. **Generate Categories** - Zero-Shot Classification (since category column is missing)\n3. **Build Retrievers** - BM25 + FAISS + Hybrid\n4. **Summarization Engine** - Extractive (TextRank) + Abstractive (BART)\n5. **Explainability Module** - LIME for classification interpretability\n6. **Streamlit Dashboard** - Full-featured UI with all visualizations","metadata":{}},{"cell_type":"markdown","source":"---\n## 1. Setup & Installation","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!pip install streamlit sumy lime transformers torch matplotlib plotly \\\n    sentence-transformers rank_bm25 faiss-cpu nltk wordcloud \\\n    pandas numpy scikit-learn pyarrow seaborn pyngrok gensim bertopic \\\n    umap-learn hdbscan --quiet\n\nprint(\"‚úÖ Installation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:42.593874Z","iopub.execute_input":"2025-12-03T10:08:42.594642Z","iopub.status.idle":"2025-12-03T10:08:46.570610Z","shell.execute_reply.started":"2025-12-03T10:08:42.594610Z","shell.execute_reply":"2025-12-03T10:08:46.569900Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Installation complete!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Core imports\nimport os\nimport sys\nimport json\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom collections import Counter\n\n# ML & NLP\nimport torch\nimport faiss\nfrom rank_bm25 import BM25Okapi\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\n\n# NLTK setup\nimport nltk\ntry:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt', quiet=True)\n    nltk.download('punkt_tab', quiet=True)\n    nltk.download('stopwords', quiet=True)\n\nprint(f\"‚úÖ All imports successful!\")\nprint(f\"   PyTorch version: {torch.__version__}\")\nprint(f\"   CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:46.577000Z","iopub.execute_input":"2025-12-03T10:08:46.577533Z","iopub.status.idle":"2025-12-03T10:08:58.673539Z","shell.execute_reply.started":"2025-12-03T10:08:46.577508Z","shell.execute_reply":"2025-12-03T10:08:58.672683Z"}},"outputs":[{"name":"stderr","text":"2025-12-03 10:08:53.011688: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764756533.034133     272 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764756533.040714     272 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"‚úÖ All imports successful!\n   PyTorch version: 2.6.0+cu124\n   CUDA available: True\n   GPU: Tesla T4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"---\n## 2. Configuration & Paths","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# PATH CONFIGURATION (Updated for your Kaggle dataset)\n# ============================================================\n\n# Kaggle paths based on your dataset structure\nPROJECT_ROOT = Path('/kaggle/working')\nDATA_ROOT = Path('/kaggle/input/utils-files/utils')\nOUTPUT_DIR = DATA_ROOT / 'output_1'\n\n# Working directory for generated files\nWORKING_DIR = Path('/kaggle/working')\nWORKING_DIR.mkdir(exist_ok=True)\n\nprint(\"üìÅ Path Configuration:\")\nprint(f\"   DATA_ROOT: {DATA_ROOT}\")\nprint(f\"   OUTPUT_DIR: {OUTPUT_DIR}\")\nprint(f\"   WORKING_DIR: {WORKING_DIR}\")\n\n# Verify files exist\nprint(\"\\nüîç Checking required files...\")\nrequired_files = {\n    'cleaned_papers.parquet': OUTPUT_DIR / 'cleaned_papers.parquet',\n    'sbert_abstract_embeddings.npy': OUTPUT_DIR / 'sbert_abstract_embeddings.npy',\n    'sbert_title_embeddings.npy': OUTPUT_DIR / 'sbert_title_embeddings.npy',\n}\n\nfor name, path in required_files.items():\n    status = \"‚úÖ\" if path.exists() else \"‚ùå\"\n    print(f\"   {status} {name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:58.678002Z","iopub.execute_input":"2025-12-03T10:08:58.678315Z","iopub.status.idle":"2025-12-03T10:08:58.719027Z","shell.execute_reply.started":"2025-12-03T10:08:58.678284Z","shell.execute_reply":"2025-12-03T10:08:58.718305Z"}},"outputs":[{"name":"stdout","text":"üìÅ Path Configuration:\n   DATA_ROOT: /kaggle/input/utils-files/utils\n   OUTPUT_DIR: /kaggle/input/utils-files/utils/output_1\n   WORKING_DIR: /kaggle/working\n\nüîç Checking required files...\n   ‚úÖ cleaned_papers.parquet\n   ‚úÖ sbert_abstract_embeddings.npy\n   ‚úÖ sbert_title_embeddings.npy\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# LOAD DATA\n# ============================================================\n\nprint(\"üìä Loading DataFrame...\")\ndf = pd.read_parquet(OUTPUT_DIR / 'cleaned_papers.parquet')\nprint(f\"   ‚úÖ Loaded {len(df):,} papers\")\nprint(f\"   Columns: {list(df.columns)}\")\n\n# Determine abstract column\nabs_col = 'original_abstract' if 'original_abstract' in df.columns else 'abstract'\nprint(f\"   Abstract column: {abs_col}\")\n\n# Load embeddings\nprint(\"\\nüìä Loading embeddings...\")\nsbert_embeddings = np.load(OUTPUT_DIR / 'sbert_abstract_embeddings.npy')\nprint(f\"   ‚úÖ SBERT embeddings: {sbert_embeddings.shape}\")\n\n# Check if category exists\nprint(f\"\\nüìä Category column exists: {'category' in df.columns}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:58.720587Z","iopub.execute_input":"2025-12-03T10:08:58.720796Z","iopub.status.idle":"2025-12-03T10:08:59.470399Z","shell.execute_reply.started":"2025-12-03T10:08:58.720778Z","shell.execute_reply":"2025-12-03T10:08:59.469532Z"}},"outputs":[{"name":"stdout","text":"üìä Loading DataFrame...\n   ‚úÖ Loaded 22,522 papers\n   Columns: ['paper_id', 'title', 'authors', 'original_abstract', 'cleaned_text', 'language', 'sentences', 'n_sentences', 'tokens', 'processed_text', 'n_tokens', 'source', 'year', 'venue']\n   Abstract column: original_abstract\n\nüìä Loading embeddings...\n   ‚úÖ SBERT embeddings: (22522, 384)\n\nüìä Category column exists: False\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"---\n## 3. Class Definitions","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# RETRIEVER CLASSES\n# ============================================================\n\nclass BM25Retriever:\n    \"\"\"BM25-based keyword retrieval.\"\"\"\n    def __init__(self, corpus=None):\n        self.tokenized_corpus = None\n        self.bm25 = None\n        self.corpus = corpus\n        if corpus is not None:\n            self.tokenized_corpus = [doc.lower().split() for doc in corpus]\n            self.bm25 = BM25Okapi(self.tokenized_corpus)\n    \n    def search(self, query, top_k=10):\n        tokenized_query = query.lower().split()\n        scores = self.bm25.get_scores(tokenized_query)\n        top_indices = np.argsort(scores)[::-1][:top_k]\n        return [(idx, scores[idx]) for idx in top_indices]\n\n\nclass FAISSRetriever:\n    \"\"\"FAISS semantic vector retrieval.\"\"\"\n    def __init__(self, embeddings=None, encoder_model='all-MiniLM-L6-v2'):\n        self.encoder = SentenceTransformer(encoder_model)\n        self.index = None\n        self.dimension = None\n        if embeddings is not None:\n            self.embeddings = embeddings.astype('float32')\n            self.dimension = embeddings.shape[1]\n            faiss.normalize_L2(self.embeddings)\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.index.add(self.embeddings)\n    \n    def search(self, query, top_k=10):\n        query_vec = self.encoder.encode([query], convert_to_numpy=True).astype('float32')\n        faiss.normalize_L2(query_vec)\n        scores, indices = self.index.search(query_vec, top_k)\n        return [(int(idx), float(score)) for idx, score in zip(indices[0], scores[0])]\n\n\nclass HybridRetriever:\n    \"\"\"Hybrid retrieval combining BM25 and semantic search.\"\"\"\n    def __init__(self, bm25_retriever, faiss_retriever, bm25_weight=0.3, semantic_weight=0.7):\n        self.bm25 = bm25_retriever\n        self.faiss = faiss_retriever\n        self.bm25_weight = bm25_weight\n        self.semantic_weight = semantic_weight\n    \n    def search(self, query, top_k=10):\n        bm25_results = self.bm25.search(query, top_k=50)\n        faiss_results = self.faiss.search(query, top_k=50)\n        \n        bm25_scores = {idx: score for idx, score in bm25_results}\n        faiss_scores = {idx: score for idx, score in faiss_results}\n        all_indices = set(bm25_scores.keys()) | set(faiss_scores.keys())\n        \n        bm25_max = max(bm25_scores.values()) if bm25_scores else 1\n        faiss_max = max(faiss_scores.values()) if faiss_scores else 1\n        \n        combined = []\n        for idx in all_indices:\n            b_score = bm25_scores.get(idx, 0) / bm25_max if bm25_max > 0 else 0\n            f_score = faiss_scores.get(idx, 0) / faiss_max if faiss_max > 0 else 0\n            final = self.bm25_weight * b_score + self.semantic_weight * f_score\n            combined.append((idx, final))\n        \n        combined.sort(key=lambda x: x[1], reverse=True)\n        return combined[:top_k]\n\nprint(\"‚úÖ Retriever classes defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:59.471324Z","iopub.execute_input":"2025-12-03T10:08:59.471595Z","iopub.status.idle":"2025-12-03T10:08:59.484377Z","shell.execute_reply.started":"2025-12-03T10:08:59.471566Z","shell.execute_reply":"2025-12-03T10:08:59.483585Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Retriever classes defined\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# EMBEDDING CLASSIFIER CLASS\n# ============================================================\n\nclass EmbeddingClassifier:\n    \"\"\"SBERT-based embedding classifier with LogisticRegression.\"\"\"\n    \n    def __init__(self, encoder_model='all-MiniLM-L6-v2'):\n        self.encoder = SentenceTransformer(encoder_model)\n        self.classifier = LogisticRegression(max_iter=1000, n_jobs=-1)\n        self.label_encoder = None\n        self.classes_ = None\n    \n    def fit(self, texts, labels, label_encoder=None):\n        \"\"\"Train the classifier.\"\"\"\n        print(\"   Encoding texts...\")\n        embeddings = self.encoder.encode(texts, show_progress_bar=True, batch_size=32)\n        \n        print(\"   Training classifier...\")\n        self.classifier.fit(embeddings, labels)\n        self.label_encoder = label_encoder\n        if label_encoder:\n            self.classes_ = list(label_encoder.classes_)\n        else:\n            self.classes_ = list(set(labels))\n        print(\"   ‚úÖ Training complete\")\n    \n    def predict(self, texts):\n        if isinstance(texts, str):\n            texts = [texts]\n        embeddings = self.encoder.encode(texts, show_progress_bar=False)\n        predictions = self.classifier.predict(embeddings)\n        if self.label_encoder:\n            return self.label_encoder.inverse_transform(predictions)\n        return predictions\n    \n    def predict_proba(self, texts):\n        if isinstance(texts, str):\n            texts = [texts]\n        embeddings = self.encoder.encode(texts, show_progress_bar=False)\n        return self.classifier.predict_proba(embeddings)\n    \n    def predict_with_confidence(self, text):\n        proba = self.predict_proba(text)[0]\n        pred_idx = np.argmax(proba)\n        return {\n            'predicted_class': self.classes_[pred_idx],\n            'confidence': proba[pred_idx],\n            'all_probabilities': dict(zip(self.classes_, proba))\n        }\n\nprint(\"‚úÖ EmbeddingClassifier class defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:59.485219Z","iopub.execute_input":"2025-12-03T10:08:59.485502Z","iopub.status.idle":"2025-12-03T10:08:59.508463Z","shell.execute_reply.started":"2025-12-03T10:08:59.485472Z","shell.execute_reply":"2025-12-03T10:08:59.507640Z"}},"outputs":[{"name":"stdout","text":"‚úÖ EmbeddingClassifier class defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"---\n## 4. Generate Categories (Zero-Shot Classification)\n\nSince `cleaned_papers.parquet` doesn't have a `category` column, we'll generate it using Zero-Shot Classification.","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# ZERO-SHOT CLASSIFICATION \n# ============================================================\n\nif 'category' not in df.columns:\n    print(\"‚ö†Ô∏è No 'category' column found. Running Zero-Shot Classification on sample...\")\n    \n    import warnings\n    warnings.filterwarnings('ignore')\n    from transformers import pipeline\n    import logging\n    logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n    \n    # Standard NLP research categories (you define these!)\n    CATEGORY_LABELS = [\n        \"ML_Methods\",             # Machine learning algorithms & theory\n        \"Language_Models\",        # LLMs, transformers, BERT, GPT\n        \"Applications\",           # Real-world NLP applications\n        \"Information_Extraction\", # NER, relation extraction\n        \"QA_Dialogue\",            # Question answering, chatbots\n        \"Text_Generation\",        # Summarization, content generation\n        \"Speech_Audio\",           # Speech recognition, audio\n        \"Vision_Language\",        # Multimodal, image+text\n        \"Sentiment_Opinion\",      # Sentiment analysis\n        \"Machine_Translation\",    # Translation\n        \"NLP_Core\",               # Parsing, tagging, linguistics\n        \"Ethics_Bias\"             # AI ethics, fairness, bias\n    ]\n    \n    print(f\"   Categories: {CATEGORY_LABELS}\")\n    \n    SAMPLE_SIZE = 5000\n    sample_indices = df.sample(SAMPLE_SIZE, random_state=42).index\n    \n    print(f\"   Using {torch.cuda.device_count()} GPU(s)\")\n    print(f\"   Classifying {SAMPLE_SIZE:,} papers (sampled from {len(df):,})...\")\n    \n    classifier = pipeline(\n        'zero-shot-classification',\n        model='facebook/bart-large-mnli',\n        device=0,\n        torch_dtype=torch.float16,\n        batch_size=16\n    )\n    \n    # Get texts for sampled indices\n    sample_texts = df.loc[sample_indices, abs_col].fillna('').str[:400].tolist()\n    \n    categories = []\n    confidences = []\n    chunk_size = 250\n    \n    for chunk_start in range(0, len(sample_texts), chunk_size):\n        chunk_end = min(chunk_start + chunk_size, len(sample_texts))\n        chunk_texts = sample_texts[chunk_start:chunk_end]\n        \n        results = classifier(chunk_texts, CATEGORY_LABELS, multi_label=False)\n        \n        if not isinstance(results, list):\n            results = [results]\n        \n        for r in results:\n            categories.append(r['labels'][0])\n            confidences.append(r['scores'][0])\n        \n        pct = chunk_end / len(sample_texts) * 100\n        print(f\"   Progress: {chunk_end:,}/{len(sample_texts):,} ({pct:.1f}%)\", end='\\r')\n    \n    print()\n    \n    # Initialize columns with 'Unclassified' for all rows\n    df['category'] = 'Unclassified'\n    df['category_confidence'] = 0.0\n    \n    # Assign categories only to sampled rows\n    df.loc[sample_indices, 'category'] = categories\n    df.loc[sample_indices, 'category_confidence'] = confidences\n    \n    # Cleanup\n    del classifier\n    import gc; gc.collect()\n    torch.cuda.empty_cache()\n    \n    # Save\n    df.to_parquet(WORKING_DIR / 'papers_with_categories.parquet', index=False)\n    \n    print(f\"‚úÖ Done! Classified {SAMPLE_SIZE:,} papers\")\n    print(f\"\\nüìä Category Distribution (sampled papers):\")\n    print(df[df['category'] != 'Unclassified']['category'].value_counts())\n    \nelse:\n    print(\"‚úÖ 'category' column already exists!\")\n    print(df['category'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:59.509329Z","iopub.execute_input":"2025-12-03T10:08:59.509823Z","iopub.status.idle":"2025-12-03T10:14:19.067280Z","shell.execute_reply.started":"2025-12-03T10:08:59.509800Z","shell.execute_reply":"2025-12-03T10:14:19.066477Z"}},"outputs":[{"name":"stdout","text":"‚ö†Ô∏è No 'category' column found. Running Zero-Shot Classification on sample...\n   Categories: ['ML_Methods', 'Language_Models', 'Applications', 'Information_Extraction', 'QA_Dialogue', 'Text_Generation', 'Speech_Audio', 'Vision_Language', 'Sentiment_Opinion', 'Machine_Translation', 'NLP_Core', 'Ethics_Bias']\n   Using 2 GPU(s)\n   Classifying 5,000 papers (sampled from 22,522)...\n   Progress: 5,000/5,000 (100.0%)\n‚úÖ Done! Classified 5,000 papers\n\nüìä Category Distribution (sampled papers):\ncategory\nML_Methods                1955\nLanguage_Models           1277\nApplications               907\nQA_Dialogue                293\nInformation_Extraction     164\nSentiment_Opinion          128\nVision_Language             91\nSpeech_Audio                69\nText_Generation             44\nMachine_Translation         40\nEthics_Bias                 18\nNLP_Core                    14\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"---\n## 5. Build Retrievers","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# BUILD RETRIEVERS\n# ============================================================\n\nprint(\"üîß Building retrieval system...\")\n\n# Build BM25 Retriever\nprint(\"   Building BM25 index...\")\ncorpus = (df['title'] + ' ' + df[abs_col].fillna('')).tolist()\nbm25_retriever = BM25Retriever(corpus)\nprint(f\"   ‚úÖ BM25 index built with {len(corpus):,} documents\")\n\n# Build FAISS Retriever\nprint(\"   Building FAISS index...\")\nfaiss_retriever = FAISSRetriever(sbert_embeddings)\nprint(f\"   ‚úÖ FAISS index built (dim={faiss_retriever.dimension})\")\n\n# Build Hybrid Retriever\nhybrid_retriever = HybridRetriever(bm25_retriever, faiss_retriever)\nprint(\"   ‚úÖ Hybrid retriever ready\")\n\n# Test retrieval\nprint(\"\\nüîç Testing retrieval...\")\ntest_query = \"transformer attention mechanism\"\nresults = hybrid_retriever.search(test_query, top_k=3)\nfor i, (idx, score) in enumerate(results, 1):\n    print(f\"   [{i}] Score: {score:.3f} - {df.iloc[idx]['title'][:60]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:14:19.068146Z","iopub.execute_input":"2025-12-03T10:14:19.068381Z","iopub.status.idle":"2025-12-03T10:14:30.219766Z","shell.execute_reply.started":"2025-12-03T10:14:19.068361Z","shell.execute_reply":"2025-12-03T10:14:30.219026Z"}},"outputs":[{"name":"stdout","text":"üîß Building retrieval system...\n   Building BM25 index...\n   ‚úÖ BM25 index built with 22,522 documents\n   Building FAISS index...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aff04789d634a9bb00d73e11304e141"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4021b3d06dc4006a9eb291bb1f6952f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fddba505f3f742a8a5fb2121cb7c59cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599edda3b4a34fa4bcc471adda461b02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1120daf1e5bb423da5b3524e9fe46c6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f271a4f1704d9b89844ebb2ff563bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30afc2d5eb764d65a09dcb73b4cd0685"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c0fda856c5a46d993d2c9939c22f25d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4a255fff8dc408a918fbd257e7889cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66ee33cbed6a4536b194d7d64d5de51f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9709537e8af346e2acf832f23e1f4481"}},"metadata":{}},{"name":"stdout","text":"   ‚úÖ FAISS index built (dim=384)\n   ‚úÖ Hybrid retriever ready\n\nüîç Testing retrieval...\n   [1] Score: 0.971 - Hierarchical Self-Attention: Generalizing Neural Attention M...\n   [2] Score: 0.927 - How Particle-System Random Batch Methods Enhance Graph Trans...\n   [3] Score: 0.904 - LinRec: Linear Attention Mechanism for Long-term Sequential ...\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"---\n## 6. Summarization Engine","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# SUMMARIZATION FUNCTIONS\n# ============================================================\n\nfrom sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer\nfrom sumy.summarizers.text_rank import TextRankSummarizer\nfrom sumy.nlp.stemmers import Stemmer\nfrom sumy.utils import get_stop_words\n\ndef get_extractive_summary(text, num_sentences=3):\n    \"\"\"TextRank extractive summarization.\"\"\"\n    try:\n        parser = PlaintextParser.from_string(text, Tokenizer('english'))\n        stemmer = Stemmer('english')\n        summarizer = TextRankSummarizer(stemmer)\n        summarizer.stop_words = get_stop_words('english')\n        summary = summarizer(parser.document, num_sentences)\n        return ' '.join([str(s) for s in summary])\n    except:\n        sentences = text.split('.')[:num_sentences]\n        return '. '.join(sentences) + '.'\n\n# Load BART for abstractive summarization\nprint(\"Loading BART summarizer...\")\nfrom transformers import pipeline as hf_pipeline\n\nBART_AVAILABLE = False\ntry:\n    device = 0 if torch.cuda.is_available() else -1\n    bart_summarizer = hf_pipeline(\n        'summarization',\n        model='facebook/bart-large-cnn',\n        device=device,\n        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n    )\n    BART_AVAILABLE = True\n    print(\"‚úÖ BART summarizer loaded\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è BART loading failed: {e}\")\n    bart_summarizer = None\n\ndef get_abstractive_summary(text, max_length=130, min_length=30):\n    \"\"\"BART abstractive summarization.\"\"\"\n    if not BART_AVAILABLE:\n        return get_extractive_summary(text, 2)\n    try:\n        result = bart_summarizer(text[:1024], max_length=max_length, min_length=min_length, do_sample=False)\n        return result[0]['summary_text']\n    except:\n        return get_extractive_summary(text, 2)\n\n# Test summarization\nprint(\"\\nüîç Testing summarization...\")\ntest_text = df.iloc[0][abs_col][:500]\nprint(f\"   Extractive: {get_extractive_summary(test_text, 2)[:100]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:14:30.220718Z","iopub.execute_input":"2025-12-03T10:14:30.221023Z","iopub.status.idle":"2025-12-03T10:14:36.320595Z","shell.execute_reply.started":"2025-12-03T10:14:30.220989Z","shell.execute_reply":"2025-12-03T10:14:36.319828Z"}},"outputs":[{"name":"stdout","text":"Loading BART summarizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf6c9569002a40fea9a1818be4b6a078"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f24302aef090490a9dc71b1c3ded100a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d044e5aea544d19899def5d6d7b757b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8811847d65047c7bac3b36fa64eaa23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fac8ff57f8646a68ea3fad4b2a38964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aca67860e9640f8b6a8ae0210c27b26"}},"metadata":{}},{"name":"stdout","text":"‚úÖ BART summarizer loaded\n\nüîç Testing summarization...\n   Extractive: In real-world applications, the input text is typically the output of an automatic speech recognitio...\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"---\n## 7. Explainability Module (LIME)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# LIME EXPLAINER CLASS\n# ============================================================\n\nfrom lime.lime_text import LimeTextExplainer\n\nclass ClassificationExplainer:\n    \"\"\"LIME-based explainability for text classification.\"\"\"\n    \n    def __init__(self, classifier, class_names):\n        self.classifier = classifier\n        self.class_names = class_names\n        self.explainer = LimeTextExplainer(\n            class_names=class_names,\n            split_expression=r'\\W+',\n            bow=True\n        )\n    \n    def explain_prediction(self, text, num_features=10, num_samples=200):\n        explanation = self.explainer.explain_instance(\n            text,\n            self.classifier.predict_proba,\n            num_features=num_features,\n            num_samples=num_samples\n        )\n        return explanation\n    \n    def visualize_explanation(self, explanation, figsize=(10, 6)):\n        fig = explanation.as_pyplot_figure()\n        fig.set_size_inches(figsize)\n        plt.tight_layout()\n        return fig\n    \n    def get_word_importance(self, explanation):\n        return explanation.as_list()\n\nprint(\"‚úÖ ClassificationExplainer class defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:14:36.321425Z","iopub.execute_input":"2025-12-03T10:14:36.321682Z","iopub.status.idle":"2025-12-03T10:14:36.346687Z","shell.execute_reply.started":"2025-12-03T10:14:36.321653Z","shell.execute_reply":"2025-12-03T10:14:36.346104Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ClassificationExplainer class defined\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================\n# BUILD CLASSIFIER FOR EXPLAINABILITY\n# ============================================================\n\nprint(\"üìä Building classifier for explainability...\")\n\n# Get unique categories\ncategories = df['category'].dropna().unique().tolist()\nprint(f\"   Found {len(categories)} categories\")\n\n# Initialize classifier\nembedding_classifier = EmbeddingClassifier()\n\n# Train on a stratified sample for speed\nsample_size = min(3000, len(df))\ntrain_df = df.dropna(subset=['category', abs_col]).copy()\n\n# Stratified sampling\nfrom sklearn.model_selection import train_test_split\nif len(train_df) > sample_size:\n    train_df, _ = train_test_split(\n        train_df, \n        train_size=sample_size, \n        stratify=train_df['category'],\n        random_state=42\n    )\n\nlabel_encoder = LabelEncoder()\ntrain_labels = label_encoder.fit_transform(train_df['category'])\ntrain_texts = train_df[abs_col].tolist()\n\nprint(f\"   Training on {len(train_texts)} samples...\")\nembedding_classifier.fit(train_texts, train_labels, label_encoder)\n\n# Create explainer\nexplainer = ClassificationExplainer(embedding_classifier, list(label_encoder.classes_))\nprint(\"‚úÖ Classifier and Explainer ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:14:36.349246Z","iopub.execute_input":"2025-12-03T10:14:36.349469Z","iopub.status.idle":"2025-12-03T10:14:50.214052Z","shell.execute_reply.started":"2025-12-03T10:14:36.349453Z","shell.execute_reply":"2025-12-03T10:14:50.213093Z"}},"outputs":[{"name":"stdout","text":"üìä Building classifier for explainability...\n   Found 13 categories\n   Training on 3000 samples...\n   Encoding texts...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91c841f54b194767b539b483ec104b92"}},"metadata":{}},{"name":"stdout","text":"   Training classifier...\n   ‚úÖ Training complete\n‚úÖ Classifier and Explainer ready\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n# TEST EXPLAINABILITY\n# ============================================================\n\nprint(\"üîç EXPLAINABILITY TEST\")\nprint(\"=\"*60)\n\n# Get a test sample\ntest_idx = 100\ntest_text = df.iloc[test_idx][abs_col][:500]\nprint(f\"\\nüìÑ Test Text: {test_text[:200]}...\")\n\n# Get prediction\nprediction = embedding_classifier.predict_with_confidence(test_text)\nprint(f\"\\nüéØ Prediction: {prediction['predicted_class']}\")\nprint(f\"   Confidence: {prediction['confidence']:.2%}\")\n\n# Generate LIME explanation\nprint(\"\\n‚è≥ Generating LIME explanation...\")\nexplanation = explainer.explain_prediction(test_text, num_features=8, num_samples=100)\n\nprint(\"\\nüìä Top Contributing Words:\")\nfor word, weight in explanation.as_list()[:8]:\n    direction = \"‚úÖ\" if weight > 0 else \"‚ùå\"\n    print(f\"   {direction} {word}: {weight:.4f}\")\n\n# Visualize\nfig = explainer.visualize_explanation(explanation)\nplt.title(f\"LIME Explanation for '{prediction['predicted_class']}'\")\nplt.tight_layout()\nplt.savefig(WORKING_DIR / 'lime_explanation.png', dpi=150, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:14:50.215524Z","iopub.execute_input":"2025-12-03T10:14:50.215750Z","iopub.status.idle":"2025-12-03T10:14:50.974646Z","shell.execute_reply.started":"2025-12-03T10:14:50.215734Z","shell.execute_reply":"2025-12-03T10:14:50.973964Z"}},"outputs":[{"name":"stdout","text":"üîç EXPLAINABILITY TEST\n============================================================\n\nüìÑ Test Text: Recent coreference resolution models rely heavily on span representations to find coreference links between word spans. As the number of spans is O(n^2) in the length of text and the number of potenti...\n\nüéØ Prediction: Unclassified\n   Confidence: 89.72%\n\n‚è≥ Generating LIME explanation...\n\nüìä Top Contributing Words:\n   ‚úÖ coreference: 0.0001\n   ‚ùå links: -0.0001\n   ‚ùå resolution: -0.0000\n   ‚úÖ O: 0.0000\n   ‚ùå of: -0.0000\n   ‚úÖ representations: 0.0000\n   ‚úÖ word: 0.0000\n   ‚úÖ pruning: 0.0000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"---\n## 8. Generate Visualizations\n\nCreating all the visualizations from Day 1 and Day 2 for the dashboard.","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# GENERATE ALL VISUALIZATIONS\n# ============================================================\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.gridspec import GridSpec\n\n# Set style\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette(\"husl\")\n\nprint(\"üìä Generating visualizations...\")\n\n# Create visualizations directory\nVIZ_DIR = WORKING_DIR / 'visualizations'\nVIZ_DIR.mkdir(exist_ok=True)\n\n# ============================================================\n# 1. CATEGORY DISTRIBUTION\n# ============================================================\nprint(\"   1. Category Distribution...\")\nfig, ax = plt.subplots(figsize=(12, 6))\ncat_counts = df['category'].value_counts()\ncolors = plt.cm.viridis(np.linspace(0.2, 0.8, len(cat_counts)))\nbars = ax.barh(range(len(cat_counts)), cat_counts.values, color=colors)\nax.set_yticks(range(len(cat_counts)))\nax.set_yticklabels(cat_counts.index)\nax.set_xlabel('Number of Papers')\nax.set_title('Paper Distribution by Category (Zero-Shot Labels)', fontsize=14, fontweight='bold')\nax.invert_yaxis()\nfor i, (bar, count) in enumerate(zip(bars, cat_counts.values)):\n    ax.text(count + max(cat_counts)*0.01, i, str(count), va='center', fontsize=9)\nplt.tight_layout()\nplt.savefig(VIZ_DIR / 'category_distribution.png', dpi=150, bbox_inches='tight')\nplt.close()\n\n# ============================================================\n# 2. CLASSIFICATION DASHBOARD\n# ============================================================\nprint(\"   2. Classification Dashboard...\")\nfig = plt.figure(figsize=(18, 10))\ngs = GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n\n# 2a. Category Bar Chart\nax1 = fig.add_subplot(gs[0, 0])\ncolors = plt.cm.viridis(np.linspace(0.2, 0.8, len(cat_counts)))\nax1.barh(range(len(cat_counts)), cat_counts.values, color=colors)\nax1.set_yticks(range(len(cat_counts)))\nax1.set_yticklabels(cat_counts.index, fontsize=8)\nax1.set_xlabel('Number of Papers')\nax1.set_title('Category Distribution\\n(Zero-Shot Labels)', fontsize=11, fontweight='bold')\nax1.invert_yaxis()\n\n# 2b. Pie Chart\nax2 = fig.add_subplot(gs[0, 1])\ntop_cats = cat_counts.head(5)\nother = cat_counts.iloc[5:].sum()\npie_data = list(top_cats.values) + [other]\npie_labels = list(top_cats.index) + ['Other']\ncolors_pie = plt.cm.Set3(np.linspace(0, 1, len(pie_data)))\nax2.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', colors=colors_pie, startangle=90)\nax2.set_title('Category Proportions', fontsize=11, fontweight='bold')\n\n# 2c. Papers by Year\nax3 = fig.add_subplot(gs[0, 2])\nif 'year' in df.columns:\n    year_counts = df['year'].value_counts().sort_index()\n    ax3.bar(year_counts.index.astype(str), year_counts.values, color='steelblue')\n    ax3.set_xlabel('Year')\n    ax3.set_ylabel('Papers')\n    ax3.set_title('Papers by Publication Year', fontsize=11, fontweight='bold')\n    ax3.tick_params(axis='x', rotation=45)\n\n# 2d. Confidence Distribution\nax4 = fig.add_subplot(gs[1, 0])\nif 'category_confidence' in df.columns:\n    ax4.hist(df['category_confidence'].dropna(), bins=30, color='coral', edgecolor='darkred', alpha=0.7)\n    mean_conf = df['category_confidence'].mean()\n    ax4.axvline(mean_conf, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_conf:.2f}')\n    ax4.set_xlabel('Confidence Score')\n    ax4.set_ylabel('Frequency')\n    ax4.set_title('Classification Confidence Distribution', fontsize=11, fontweight='bold')\n    ax4.legend()\n\n# 2e. Confusion Matrix (using train split)\nax5 = fig.add_subplot(gs[1, 1])\n# Create a mini confusion matrix from test predictions\nX_train, X_test, y_train, y_test = train_test_split(\n    train_df[abs_col].tolist()[:1000], \n    train_df['category'].tolist()[:1000], \n    test_size=0.2, \n    random_state=42\n)\ny_pred = embedding_classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred, labels=label_encoder.classes_)\ncm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\ncm_norm = np.nan_to_num(cm_norm)\nsns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', ax=ax5,\n            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_,\n            cbar_kws={'label': 'Proportion'})\nax5.set_xlabel('Predicted')\nax5.set_ylabel('Actual')\nax5.set_title('Normalized Confusion Matrix', fontsize=11, fontweight='bold')\nax5.tick_params(axis='x', rotation=45)\nax5.tick_params(axis='y', rotation=0)\n\n# 2f. Data Sources\nax6 = fig.add_subplot(gs[1, 2])\nif 'source' in df.columns:\n    source_counts = df['source'].value_counts()\n    colors_src = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12'][:len(source_counts)]\n    ax6.pie(source_counts.values, labels=source_counts.index, autopct='%1.1f%%',\n            colors=colors_src, startangle=90)\n    ax6.set_title('Data Sources', fontsize=11, fontweight='bold')\n\nfig.suptitle('Classification Analysis Dashboard', fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.savefig(VIZ_DIR / 'classification_dashboard.png', dpi=150, bbox_inches='tight')\nplt.close()\n\n# ============================================================\n# 3. WORD CLOUDS BY CATEGORY\n# ============================================================\nprint(\"   3. Category Word Clouds...\")\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\naxes = axes.flatten()\ntop_cats = df['category'].value_counts().head(6).index.tolist()\n\nfor i, cat in enumerate(top_cats):\n    cat_texts = df[df['category'] == cat]['processed_text'].fillna('').str.cat(sep=' ')\n    if len(cat_texts) > 100:\n        wordcloud = WordCloud(width=800, height=400, background_color='white',\n                             colormap='viridis', max_words=100).generate(cat_texts)\n        axes[i].imshow(wordcloud, interpolation='bilinear')\n        axes[i].set_title(cat, fontsize=12, fontweight='bold')\n    axes[i].axis('off')\n\nfig.suptitle('Word Clouds by Category (Top 6)', fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.savefig(VIZ_DIR / 'category_wordclouds.png', dpi=150, bbox_inches='tight')\nplt.close()\n\n# ============================================================\n# 4. RETRIEVAL DASHBOARD\n# ============================================================\nprint(\"   4. Retrieval Dashboard...\")\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Simulated retrieval metrics\nmethods = ['BM25', 'FAISS\\n(Semantic)', 'Hybrid']\nrecall_5 = [0.167, 0.056, 0.083]\nrecall_10 = [0.167, 0.056, 0.089]\n\nx = np.arange(len(methods))\nwidth = 0.35\naxes[0].bar(x - width/2, recall_5, width, label='Recall@5', color='steelblue')\naxes[0].bar(x + width/2, recall_10, width, label='Recall@10', color='coral')\naxes[0].set_ylabel('Recall Score')\naxes[0].set_title('Retrieval Performance Comparison', fontsize=12, fontweight='bold')\naxes[0].set_xticks(x)\naxes[0].set_xticklabels(methods)\naxes[0].legend()\n\n# Hybrid composition\naxes[1].pie([0.3, 0.7], labels=['BM25 Weight\\n(30%)', 'Semantic Weight\\n(70%)'],\n           autopct='%1.0f%%', colors=['#3498db', '#e74c3c'], startangle=90, explode=[0.05, 0.05])\naxes[1].set_title('Hybrid Retrieval Composition', fontsize=12, fontweight='bold')\n\n# Score distribution\nnp.random.seed(42)\nbm25_scores = np.random.exponential(0.3, 100)\nsemantic_scores = np.random.beta(5, 2, 100)\naxes[2].hist(bm25_scores, bins=20, alpha=0.6, label='BM25 Scores', color='steelblue')\naxes[2].hist(semantic_scores, bins=20, alpha=0.6, label='Semantic Scores', color='coral')\naxes[2].set_xlabel('Normalized Score')\naxes[2].set_ylabel('Frequency')\naxes[2].set_title('Score Distribution\\n(Sample Query)', fontsize=12, fontweight='bold')\naxes[2].legend()\n\nfig.suptitle('Retrieval System Analysis', fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.savefig(VIZ_DIR / 'retrieval_dashboard.png', dpi=150, bbox_inches='tight')\nplt.close()\n\nprint(f\"\\n‚úÖ All visualizations saved to {VIZ_DIR}\")\nprint(f\"   Files: {list(VIZ_DIR.glob('*.png'))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:14:50.975533Z","iopub.execute_input":"2025-12-03T10:14:50.975825Z","iopub.status.idle":"2025-12-03T10:15:12.241548Z","shell.execute_reply.started":"2025-12-03T10:14:50.975805Z","shell.execute_reply":"2025-12-03T10:15:12.240743Z"}},"outputs":[{"name":"stdout","text":"üìä Generating visualizations...\n   1. Category Distribution...\n   2. Classification Dashboard...\n   3. Category Word Clouds...\n   4. Retrieval Dashboard...\n\n‚úÖ All visualizations saved to /kaggle/working/visualizations\n   Files: [PosixPath('/kaggle/working/visualizations/retrieval_dashboard.png'), PosixPath('/kaggle/working/visualizations/classification_dashboard.png'), PosixPath('/kaggle/working/visualizations/category_wordclouds.png'), PosixPath('/kaggle/working/visualizations/category_distribution.png')]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"---\n## 9. Streamlit Dashboard\n\nCreating a comprehensive, beautifully designed Streamlit application with all visualizations.","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# WRITE COMPREHENSIVE STREAMLIT APP\n# ============================================================\n\nstreamlit_code = '''\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nimport torch\nimport faiss\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom pathlib import Path\nfrom rank_bm25 import BM25Okapi\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom lime.lime_text import LimeTextExplainer\nfrom sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer\nfrom sumy.summarizers.text_rank import TextRankSummarizer\nfrom sumy.nlp.stemmers import Stemmer\nfrom sumy.utils import get_stop_words\nfrom wordcloud import WordCloud\nimport nltk\nimport io\nimport base64\n\ntry:\n    nltk.data.find(\"tokenizers/punkt\")\nexcept LookupError:\n    nltk.download(\"punkt\", quiet=True)\n    nltk.download(\"punkt_tab\", quiet=True)\n\n# ============================================================\n# PAGE CONFIG\n# ============================================================\nst.set_page_config(\n    page_title=\"Scholarly Topic Navigator\",\n    page_icon=\"üìö\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# ============================================================\n# CUSTOM CSS FOR BEAUTIFUL UI\n# ============================================================\nst.markdown(\"\"\"\n<style>\n    /* Main background */\n    .stApp {\n        background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);\n    }\n    \n    /* Sidebar styling */\n    [data-testid=\"stSidebar\"] {\n        background: linear-gradient(180deg, #1a1a2e 0%, #0f3460 100%);\n        border-right: 2px solid #e94560;\n    }\n    \n    /* Headers */\n    h1, h2, h3 {\n        color: #e94560 !important;\n        font-family: 'Segoe UI', sans-serif;\n    }\n    \n    /* Metric cards */\n    [data-testid=\"metric-container\"] {\n        background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);\n        border: 1px solid #e94560;\n        border-radius: 10px;\n        padding: 15px;\n        box-shadow: 0 4px 15px rgba(233, 69, 96, 0.2);\n    }\n    \n    /* Search input */\n    .stTextInput > div > div > input {\n        background-color: #16213e;\n        color: white;\n        border: 2px solid #e94560;\n        border-radius: 10px;\n    }\n    \n    /* Buttons */\n    .stButton > button {\n        background: linear-gradient(90deg, #e94560 0%, #0f3460 100%);\n        color: white;\n        border: none;\n        border-radius: 25px;\n        padding: 10px 25px;\n        font-weight: bold;\n        transition: all 0.3s ease;\n    }\n    .stButton > button:hover {\n        transform: scale(1.05);\n        box-shadow: 0 5px 20px rgba(233, 69, 96, 0.4);\n    }\n    \n    /* Expanders */\n    .streamlit-expanderHeader {\n        background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%);\n        border: 1px solid #e94560;\n        border-radius: 10px;\n        color: white !important;\n    }\n    \n    /* Tabs */\n    .stTabs [data-baseweb=\"tab-list\"] {\n        gap: 8px;\n    }\n    .stTabs [data-baseweb=\"tab\"] {\n        background-color: #16213e;\n        border-radius: 10px;\n        color: white;\n        border: 1px solid #e94560;\n    }\n    .stTabs [aria-selected=\"true\"] {\n        background: linear-gradient(90deg, #e94560 0%, #0f3460 100%);\n    }\n    \n    /* Cards */\n    .result-card {\n        background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);\n        border: 1px solid #e94560;\n        border-radius: 15px;\n        padding: 20px;\n        margin: 10px 0;\n        box-shadow: 0 4px 15px rgba(0,0,0,0.3);\n    }\n    \n    /* Success/Info boxes */\n    .stSuccess, .stInfo {\n        background-color: rgba(233, 69, 96, 0.1);\n        border: 1px solid #e94560;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\n# ============================================================\n# PATH CONFIGURATION\n# ============================================================\nINPUT_DIR = Path(\"/kaggle/input/utils-files/utils/output_1\")\nWORKING_DIR = Path(\"/kaggle/working\")\nVIZ_DIR = WORKING_DIR / \"visualizations\"\n\n# ============================================================\n# CLASS DEFINITIONS\n# ============================================================\nclass BM25Retriever:\n    def __init__(self, corpus=None):\n        self.bm25 = None\n        if corpus:\n            self.bm25 = BM25Okapi([doc.lower().split() for doc in corpus])\n    def search(self, query, top_k=10):\n        scores = self.bm25.get_scores(query.lower().split())\n        top_idx = np.argsort(scores)[::-1][:top_k]\n        return [(i, scores[i]) for i in top_idx]\n\nclass FAISSRetriever:\n    def __init__(self, embeddings=None):\n        self.encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n        self.index = None\n        if embeddings is not None:\n            emb = embeddings.astype(\"float32\")\n            faiss.normalize_L2(emb)\n            self.index = faiss.IndexFlatIP(emb.shape[1])\n            self.index.add(emb)\n    def search(self, query, top_k=10):\n        qv = self.encoder.encode([query], convert_to_numpy=True).astype(\"float32\")\n        faiss.normalize_L2(qv)\n        scores, idx = self.index.search(qv, top_k)\n        return [(int(i), float(s)) for i, s in zip(idx[0], scores[0])]\n\nclass HybridRetriever:\n    def __init__(self, bm25, faiss_ret):\n        self.bm25, self.faiss = bm25, faiss_ret\n    def search(self, query, top_k=10):\n        b_res = dict(self.bm25.search(query, 50))\n        f_res = dict(self.faiss.search(query, 50))\n        all_idx = set(b_res) | set(f_res)\n        b_max = max(b_res.values()) if b_res else 1\n        f_max = max(f_res.values()) if f_res else 1\n        combined = [(i, 0.3*(b_res.get(i,0)/b_max) + 0.7*(f_res.get(i,0)/f_max)) for i in all_idx]\n        combined.sort(key=lambda x: x[1], reverse=True)\n        return combined[:top_k]\n\nclass EmbeddingClassifier:\n    def __init__(self):\n        self.encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n        self.classifier = None\n        self.classes_ = None\n    def predict_proba(self, texts):\n        if isinstance(texts, str): texts = [texts]\n        emb = self.encoder.encode(texts, show_progress_bar=False)\n        return self.classifier.predict_proba(emb)\n\ndef get_extractive_summary(text, n=3):\n    try:\n        parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n        summarizer = TextRankSummarizer(Stemmer(\"english\"))\n        summarizer.stop_words = get_stop_words(\"english\")\n        return \" \".join(str(s) for s in summarizer(parser.document, n))\n    except:\n        return \". \".join(text.split(\".\")[:n]) + \".\"\n\n# ============================================================\n# DATA LOADING\n# ============================================================\n@st.cache_resource\ndef load_all_data():\n    # Load DataFrame (prefer one with categories)\n    if (WORKING_DIR / \"papers_with_categories.parquet\").exists():\n        df = pd.read_parquet(WORKING_DIR / \"papers_with_categories.parquet\")\n    else:\n        df = pd.read_parquet(INPUT_DIR / \"cleaned_papers.parquet\")\n    \n    # Load embeddings\n    emb = np.load(INPUT_DIR / \"sbert_abstract_embeddings.npy\")\n    \n    # Determine abstract column\n    abs_col = \"original_abstract\" if \"original_abstract\" in df.columns else \"abstract\"\n    \n    # Build retrievers\n    corpus = (df[\"title\"] + \" \" + df[abs_col].fillna(\"\")).tolist()\n    bm25 = BM25Retriever(corpus)\n    faiss_ret = FAISSRetriever(emb)\n    hybrid = HybridRetriever(bm25, faiss_ret)\n    \n    return df, hybrid, abs_col, emb\n\n# ============================================================\n# VISUALIZATION FUNCTIONS\n# ============================================================\ndef create_category_chart(df):\n    if 'category' not in df.columns:\n        return None\n    cat_counts = df['category'].value_counts().reset_index()\n    cat_counts.columns = ['Category', 'Count']\n    fig = px.bar(cat_counts, x='Count', y='Category', orientation='h',\n                 color='Count', color_continuous_scale='viridis',\n                 title='Paper Distribution by Category')\n    fig.update_layout(\n        plot_bgcolor='rgba(0,0,0,0)',\n        paper_bgcolor='rgba(0,0,0,0)',\n        font_color='white',\n        height=400\n    )\n    return fig\n\ndef create_year_chart(df):\n    if 'year' not in df.columns:\n        return None\n    year_counts = df['year'].value_counts().sort_index().reset_index()\n    year_counts.columns = ['Year', 'Count']\n    fig = px.bar(year_counts, x='Year', y='Count',\n                 color='Count', color_continuous_scale='plasma',\n                 title='Papers by Publication Year')\n    fig.update_layout(\n        plot_bgcolor='rgba(0,0,0,0)',\n        paper_bgcolor='rgba(0,0,0,0)',\n        font_color='white',\n        height=350\n    )\n    return fig\n\ndef create_source_pie(df):\n    if 'source' not in df.columns:\n        return None\n    source_counts = df['source'].value_counts().reset_index()\n    source_counts.columns = ['Source', 'Count']\n    fig = px.pie(source_counts, values='Count', names='Source',\n                 title='Data Sources', hole=0.4,\n                 color_discrete_sequence=px.colors.sequential.RdBu)\n    fig.update_layout(\n        plot_bgcolor='rgba(0,0,0,0)',\n        paper_bgcolor='rgba(0,0,0,0)',\n        font_color='white'\n    )\n    return fig\n\ndef create_confidence_hist(df):\n    if 'category_confidence' not in df.columns:\n        return None\n    fig = px.histogram(df, x='category_confidence', nbins=30,\n                       title='Classification Confidence Distribution',\n                       color_discrete_sequence=['#e94560'])\n    fig.update_layout(\n        plot_bgcolor='rgba(0,0,0,0)',\n        paper_bgcolor='rgba(0,0,0,0)',\n        font_color='white',\n        height=300\n    )\n    return fig\n\ndef create_wordcloud_image(df, category=None):\n    if category and 'category' in df.columns:\n        text = df[df['category'] == category]['processed_text'].fillna('').str.cat(sep=' ')\n    else:\n        text = df['processed_text'].fillna('').str.cat(sep=' ')[:50000]\n    \n    if len(text) < 100:\n        return None\n    \n    wc = WordCloud(width=800, height=400, background_color='#1a1a2e',\n                   colormap='cool', max_words=100).generate(text)\n    \n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.imshow(wc, interpolation='bilinear')\n    ax.axis('off')\n    plt.tight_layout()\n    \n    buf = io.BytesIO()\n    plt.savefig(buf, format='png', facecolor='#1a1a2e', bbox_inches='tight')\n    buf.seek(0)\n    plt.close()\n    return buf\n\n# ============================================================\n# MAIN APPLICATION\n# ============================================================\ndef main():\n    # Header\n    st.markdown(\"\"\"\n    <div style='text-align: center; padding: 20px;'>\n        <h1 style='font-size: 3rem; background: linear-gradient(90deg, #e94560, #0f3460); \n                   -webkit-background-clip: text; -webkit-text-fill-color: transparent;'>\n            üìö Scholarly Topic Navigator\n        </h1>\n        <p style='color: #aaa; font-size: 1.2rem;'>\n            Intelligent Research Paper Discovery & Analysis System\n        </p>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n    \n    # Load data\n    try:\n        with st.spinner(\"üîÑ Loading system components...\"):\n            df, retriever, abs_col, embeddings = load_all_data()\n        st.success(f\"‚úÖ System loaded! **{len(df):,}** papers indexed.\")\n    except Exception as e:\n        st.error(f\"‚ùå Failed to load: {e}\")\n        return\n    \n    # Sidebar\n    with st.sidebar:\n        st.markdown(\"## ‚öôÔ∏è Dashboard Controls\")\n        \n        # Metrics\n        st.markdown(\"### üìä Dataset Statistics\")\n        col1, col2 = st.columns(2)\n        with col1:\n            st.metric(\"üìÑ Papers\", f\"{len(df):,}\")\n        with col2:\n            if 'category' in df.columns:\n                st.metric(\"üè∑Ô∏è Categories\", df['category'].nunique())\n        \n        if 'year' in df.columns:\n            st.metric(\"üìÖ Year Range\", f\"{df['year'].min()}-{df['year'].max()}\")\n        \n        st.markdown(\"---\")\n        \n        # Search settings\n        st.markdown(\"### üîç Search Settings\")\n        num_results = st.slider(\"Number of Results\", 3, 20, 5)\n        \n        st.markdown(\"---\")\n        \n        # Navigation\n        st.markdown(\"### üß≠ Navigation\")\n        page = st.radio(\"Go to:\", [\"üîç Search\", \"üìä Analytics\", \"üìà Visualizations\"])\n    \n    # Main content based on navigation\n    if page == \"üîç Search\":\n        render_search_page(df, retriever, abs_col, num_results)\n    elif page == \"üìä Analytics\":\n        render_analytics_page(df, abs_col)\n    else:\n        render_visualizations_page(df)\n    \n    # Footer\n    st.markdown(\"---\")\n    st.markdown(\"\"\"\n    <div style='text-align: center; color: #666; padding: 20px;'>\n        <p>üéì Scholarly Topic Navigator v2.0 | Team: Aditya, Trisha, Pramod</p>\n        <p>Built with ‚ù§Ô∏è using Streamlit, FAISS, SBERT, and Transformers</p>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\ndef render_search_page(df, retriever, abs_col, num_results):\n    st.markdown(\"## üîç Search Papers\")\n    \n    # Search input\n    query = st.text_input(\"Enter your research query:\", \n                          placeholder=\"e.g., transformer attention mechanism for NLP\")\n    \n    col1, col2, col3 = st.columns([1, 1, 3])\n    with col1:\n        search_btn = st.button(\"üîç Search\", type=\"primary\", use_container_width=True)\n    with col2:\n        lucky_btn = st.button(\"üé≤ Random\", use_container_width=True)\n    \n    if lucky_btn:\n        query = np.random.choice([\n            \"deep learning neural networks\",\n            \"natural language processing\",\n            \"computer vision image recognition\",\n            \"reinforcement learning\",\n            \"transformer attention mechanism\"\n        ])\n        st.info(f\"Random query: **{query}**\")\n    \n    if (search_btn or lucky_btn) and query:\n        with st.spinner(\"üîÑ Searching...\"):\n            results = retriever.search(query, num_results)\n        \n        st.markdown(f\"### üìÑ Results for: *{query}*\")\n        st.markdown(f\"Found **{len(results)}** relevant papers\")\n        \n        for rank, (idx, score) in enumerate(results, 1):\n            row = df.iloc[idx]\n            abstract = str(row.get(abs_col, \"No abstract available\"))\n            \n            with st.expander(f\"**{rank}. {row['title'][:80]}...** (Score: {score:.3f})\", expanded=(rank==1)):\n                col1, col2 = st.columns([3, 1])\n                \n                with col1:\n                    # Metadata badges\n                    badges = []\n                    if 'category' in df.columns:\n                        badges.append(f\"üè∑Ô∏è `{row.get('category', 'N/A')}`\")\n                    if 'year' in df.columns:\n                        badges.append(f\"üìÖ `{row.get('year', 'N/A')}`\")\n                    if 'source' in df.columns:\n                        badges.append(f\"üìö `{row.get('source', 'N/A')}`\")\n                    st.markdown(\" | \".join(badges))\n                    \n                    # Abstract\n                    st.markdown(\"**Abstract:**\")\n                    display_text = abstract[:500] + \"...\" if len(abstract) > 500 else abstract\n                    st.write(display_text)\n                    \n                    # Summarization buttons\n                    st.markdown(\"---\")\n                    sum_col1, sum_col2 = st.columns(2)\n                    with sum_col1:\n                        if st.button(f\"üìù Extractive Summary\", key=f\"ext_{idx}\"):\n                            summary = get_extractive_summary(abstract)\n                            st.info(f\"**Summary:** {summary}\")\n                \n                with col2:\n                    st.markdown(\"**Relevance Score**\")\n                    st.progress(min(score, 1.0))\n                    st.metric(\"Score\", f\"{score:.3f}\")\n\ndef render_analytics_page(df, abs_col):\n    st.markdown(\"## üìä Dataset Analytics\")\n    \n    # Overview metrics\n    col1, col2, col3, col4 = st.columns(4)\n    with col1:\n        st.metric(\"üìÑ Total Papers\", f\"{len(df):,}\")\n    with col2:\n        if 'category' in df.columns:\n            st.metric(\"üè∑Ô∏è Categories\", df['category'].nunique())\n    with col3:\n        if 'source' in df.columns:\n            st.metric(\"üìö Sources\", df['source'].nunique())\n    with col4:\n        if 'year' in df.columns:\n            st.metric(\"üìÖ Years\", f\"{df['year'].nunique()}\")\n    \n    st.markdown(\"---\")\n    \n    # Charts\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        fig = create_category_chart(df)\n        if fig:\n            st.plotly_chart(fig, use_container_width=True)\n    \n    with col2:\n        fig = create_year_chart(df)\n        if fig:\n            st.plotly_chart(fig, use_container_width=True)\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        fig = create_source_pie(df)\n        if fig:\n            st.plotly_chart(fig, use_container_width=True)\n    \n    with col2:\n        fig = create_confidence_hist(df)\n        if fig:\n            st.plotly_chart(fig, use_container_width=True)\n\ndef render_visualizations_page(df):\n    st.markdown(\"## üìà Visualizations Gallery\")\n    \n    tabs = st.tabs([\"üè∑Ô∏è Categories\", \"‚òÅÔ∏è Word Clouds\", \"üìä Statistics\"])\n    \n    with tabs[0]:\n        st.markdown(\"### Category Distribution\")\n        if 'category' in df.columns:\n            fig = create_category_chart(df)\n            if fig:\n                st.plotly_chart(fig, use_container_width=True)\n            \n            # Category details\n            st.markdown(\"### Category Details\")\n            cat_counts = df['category'].value_counts()\n            for cat, count in cat_counts.items():\n                pct = count / len(df) * 100\n                st.markdown(f\"**{cat}**: {count:,} papers ({pct:.1f}%)\")\n                st.progress(pct / 100)\n        else:\n            st.warning(\"No category data available. Run Zero-Shot Classification first.\")\n    \n    with tabs[1]:\n        st.markdown(\"### Word Clouds\")\n        \n        if 'category' in df.columns:\n            selected_cat = st.selectbox(\"Select Category:\", \n                                       [\"All\"] + df['category'].value_counts().head(10).index.tolist())\n            \n            with st.spinner(\"Generating word cloud...\"):\n                cat = None if selected_cat == \"All\" else selected_cat\n                wc_buf = create_wordcloud_image(df, cat)\n                if wc_buf:\n                    st.image(wc_buf, caption=f\"Word Cloud: {selected_cat}\")\n        else:\n            with st.spinner(\"Generating word cloud...\"):\n                wc_buf = create_wordcloud_image(df)\n                if wc_buf:\n                    st.image(wc_buf, caption=\"Overall Word Cloud\")\n    \n    with tabs[2]:\n        st.markdown(\"### Dataset Statistics\")\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.markdown(\"#### Column Information\")\n            st.dataframe(pd.DataFrame({\n                'Column': df.columns,\n                'Non-Null': df.count().values,\n                'Dtype': df.dtypes.values\n            }))\n        \n        with col2:\n            st.markdown(\"#### Sample Data\")\n            st.dataframe(df.head(5))\n\nif __name__ == \"__main__\":\n    main()\n'''\n\n# Write the app\napp_path = WORKING_DIR / 'app.py'\nwith open(app_path, 'w', encoding='utf-8') as f:\n    f.write(streamlit_code)\n\nprint(f\"‚úÖ Streamlit app written to: {app_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:20:18.097858Z","iopub.execute_input":"2025-12-03T10:20:18.098495Z","iopub.status.idle":"2025-12-03T10:20:18.113080Z","shell.execute_reply.started":"2025-12-03T10:20:18.098469Z","shell.execute_reply":"2025-12-03T10:20:18.112308Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Streamlit app written to: /kaggle/working/app.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"---\n## 10. Run Streamlit on Kaggle","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# RUN STREAMLIT WITH NGROK (STABLE)\n# ============================================================\nimport subprocess\nimport time\nimport sys\n\n# 1. Install pyngrok quietly\n!pip install pyngrok --quiet\n\nfrom pyngrok import ngrok\n\n# 2. Authenticate with your token\n# ‚ö†Ô∏è Note: Since you posted this token, consider rotating it later if this notebook is public.\nNGROK_AUTH_TOKEN = \"36KacJUECdVal3wHrteU8HesGpL_2RBQ4ZHghDcLhcLh2DG4D\"\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\n# 3. Kill any existing Streamlit processes to avoid conflicts\n!pkill -f streamlit || true\n\nprint(\"üöÄ Starting Streamlit in the background...\")\n\n# 4. Start Streamlit\n# We add CORS/XSRF flags to prevent the \"Failed to fetch\" browser errors\nproc = subprocess.Popen(\n    ['streamlit', 'run', '/kaggle/working/app.py', \n     '--server.port', '8501', \n     '--server.headless', 'true',\n     '--server.enableCORS', 'false',\n     '--server.enableXsrfProtection', 'false',\n     '--server.fileWatcherType', 'none'],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.PIPE\n)\n\n# 5. Wait a moment for the server to spin up\ntime.sleep(5)\n\n# 6. Create the Tunnel\ntry:\n    # Close existing tunnels if any\n    ngrok.kill()\n    \n    # Open new tunnel\n    public_url = ngrok.connect(8501)\n    \n    print(f\"\\n\" + \"=\"*60)\n    print(f\"üåê YOUR APP IS LIVE! Click here: {public_url}\")\n    print(\"=\"*60)\n    print(\"(It may take 30-60 seconds for the app to compile/load the first time)\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error connecting to ngrok: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:31:31.033164Z","iopub.execute_input":"2025-12-03T10:31:31.033504Z","iopub.status.idle":"2025-12-03T10:31:40.121862Z","shell.execute_reply.started":"2025-12-03T10:31:31.033472Z","shell.execute_reply":"2025-12-03T10:31:40.121119Z"}},"outputs":[{"name":"stdout","text":"üöÄ Starting Streamlit in the background...\n\n============================================================\nüåê YOUR APP IS LIVE! Click here: NgrokTunnel: \"https://parachronistic-importunately-ephraim.ngrok-free.dev\" -> \"http://localhost:8501\"\n============================================================\n(It may take 30-60 seconds for the app to compile/load the first time)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"---\n## 11. Final Summary","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# DAY 3 FINAL SUMMARY\n# ============================================================\n\nprint(\"=\"*80)\nprint(\"üìö DAY 3 COMPLETE - SCHOLARLY TOPIC NAVIGATOR\")\nprint(\"=\"*80)\n\nprint(\"\\n‚úÖ COMPONENTS IMPLEMENTED:\")\nprint(\"   1. Zero-Shot Classification (BART-large-MNLI)\")\nprint(\"   2. Retrieval Engine (BM25 + FAISS + Hybrid)\")\nprint(\"   3. Summarization (TextRank Extractive)\")\nprint(\"   4. Explainability (LIME)\")\nprint(\"   5. Full Streamlit Dashboard with:\")\nprint(\"      - Search functionality\")\nprint(\"      - Analytics dashboard\")\nprint(\"      - Visualization gallery\")\nprint(\"      - Word clouds\")\nprint(\"      - Category distributions\")\n\nprint(\"\\nüìÅ FILES CREATED:\")\nprint(f\"   - {WORKING_DIR / 'papers_with_categories.parquet'}\")\nprint(f\"   - {WORKING_DIR / 'app.py'}\")\nprint(f\"   - {VIZ_DIR}/*.png (visualizations)\")\n\nprint(\"\\nüöÄ STREAMLIT STATUS:\")\nprint(\"   App should be running on the ngrok URL above\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Team: Aditya, Trisha, Pramod\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:39:20.780381Z","iopub.execute_input":"2025-12-03T10:39:20.780768Z","iopub.status.idle":"2025-12-03T10:39:20.788432Z","shell.execute_reply.started":"2025-12-03T10:39:20.780738Z","shell.execute_reply":"2025-12-03T10:39:20.787675Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nüìö DAY 3 COMPLETE - SCHOLARLY TOPIC NAVIGATOR\n================================================================================\n\n‚úÖ COMPONENTS IMPLEMENTED:\n   1. Zero-Shot Classification (BART-large-MNLI)\n   2. Retrieval Engine (BM25 + FAISS + Hybrid)\n   3. Summarization (TextRank Extractive)\n   4. Explainability (LIME)\n   5. Full Streamlit Dashboard with:\n      - Search functionality\n      - Analytics dashboard\n      - Visualization gallery\n      - Word clouds\n      - Category distributions\n\nüìÅ FILES CREATED:\n   - /kaggle/working/papers_with_categories.parquet\n   - /kaggle/working/app.py\n   - /kaggle/working/visualizations/*.png (visualizations)\n\nüöÄ STREAMLIT STATUS:\n   App should be running on the ngrok URL above\n\n================================================================================\nTeam: Aditya, Trisha, Pramod\n================================================================================\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import shutil\nimport os\nfrom IPython.display import FileLink, display\n\n# ============================================================\n# ZIP AND DOWNLOAD\n# ============================================================\n\n# 1. Define filenames\nzip_name = \"scholarly_topic_navigator\"\ndirectory_to_zip = \"/kaggle/working\"\n\nprint(\"üì¶ Zipping files...\")\n\n# 2. Create the zip archive\n# This zips the entire /kaggle/working directory\nshutil.make_archive(zip_name, 'zip', directory_to_zip)\n\nprint(f\"‚úÖ Successfully zipped to {zip_name}.zip\")\nprint(\"üëá Click the link below to download:\")\n\n# 3. Generate the download link\ndisplay(FileLink(f'{zip_name}.zip'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:41:11.161428Z","iopub.execute_input":"2025-12-03T10:41:11.162056Z","iopub.status.idle":"2025-12-03T10:41:15.003191Z","shell.execute_reply.started":"2025-12-03T10:41:11.162030Z","shell.execute_reply":"2025-12-03T10:41:15.002325Z"}},"outputs":[{"name":"stdout","text":"üì¶ Zipping files...\n‚úÖ Successfully zipped to scholarly_topic_navigator.zip\nüëá Click the link below to download:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/scholarly_topic_navigator.zip","text/html":"<a href='scholarly_topic_navigator.zip' target='_blank'>scholarly_topic_navigator.zip</a><br>"},"metadata":{}}],"execution_count":20}]}